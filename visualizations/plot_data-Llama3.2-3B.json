{"Full Model Quantization": [[8, 6, 5, 4, 3, 2], [0.5215200330441966, 0.5187938868236266, 0.5125980999586948, 0.4578273440726972, 0.060057827344072695, 0.0]], "Attention Quantization": [[8, 6, 5, 4, 3, 2], [0.5220983064849236, 0.5222635274679884, 0.521602643535729, 0.5084675753820735, 0.4483271375464684, 0.0]], "MLP Quantization": [[8, 6, 5, 4, 3, 2], [0.521602643535729, 0.5197026022304833, 0.5181330028913672, 0.49566294919454773, 0.1708384964890541, 0.005121850475010326]], "LM Head Quantization": [[8, 6, 5, 4, 3, 2], [0.5225939694341182, 0.5218504750103263, 0.5219330855018587, 0.512267657992565, 0.502519619991739, 0.20388269310202395]]}