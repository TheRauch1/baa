{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "original_model_benchmarks": {
        "wikitext_accuracy": 0.5299508376688463,
        "mmlu_results": {
            "overall_score": 0.6165644171779141,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.67,\"1\":0.73,\"2\":0.4841269841}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIn the year 2154, the world had finally reached a point of perfect harmony. After centuries of wars, conflicts, and environmental disasters, humanity had come together to form a united global government, dedicated to the well-being of all people and the planet.\n\nThe city of New Eden, a marvel of modern technology, was the capital of this new world order. Towering skyscrapers made of sustainable materials stretched towards the sky, their exteriors covered in lush greenery and"
    },
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.14106559753418
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.127853393554688
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.958942413330078
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.50315284729004
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.985475540161133
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.556482315063477
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.11443328857422
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.914579391479492
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.6490535736084
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.515790939331055
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.352324485778809
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.829011917114258
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.36848258972168
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 31.429115295410156
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.825490951538086
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.333206176757812
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.13400936126709
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.904874801635742
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.412918090820312
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.480987548828125
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.61260986328125
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.64958381652832
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.91463851928711
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.599414825439453
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.649169921875
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.197772979736328
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.019754409790039
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.527374267578125
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.542724609375
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.62854766845703
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.353055953979492
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.212955474853516
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.26140785217285
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.0695219039917
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.33424949645996
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.919906616210938
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.996826171875
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.602218627929688
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.467498779296875
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.40739631652832
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.219467163085938
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.219711303710938
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.321332931518555
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.064706802368164
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.063547134399414
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 19.892946243286133
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.043170928955078
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.484901428222656
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.285011291503906
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.765031814575195
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.158968925476074
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.435253143310547
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 19.96180534362793
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.918149948120117
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.73048210144043
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.082012176513672
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.0919246673584
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.2072696685791
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.595983505249023
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.22020149230957
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.036209106445312
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.710982322692871
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.029239654541016
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.574695587158203
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.729000091552734
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.51182746887207
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.96198081970215
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.105640411376953
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.821223258972168
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.971294403076172
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.31842613220215
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.197134017944336
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.885272979736328
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.221525192260742
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.049198150634766
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.774961471557617
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.909133911132812
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.94943618774414
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.86412239074707
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.513324737548828
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.222993850708008
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.04498291015625
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.73885726928711
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.968280792236328
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.61220359802246
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.19076919555664
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.57425308227539
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.38320541381836
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.139101028442383
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.86087417602539
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.1988525390625
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.097177505493164
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.989078521728516
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.497575759887695
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.6290225982666
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.49935531616211
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.872308731079102
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.906147003173828
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.586881637573242
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.103775024414062
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.041390419006348
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.198469161987305
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.49110984802246
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.502193450927734
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.963397979736328
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.132266998291016
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.11350440979004
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.022476196289062
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.41718292236328
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.809032440185547
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.526369094848633
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.12396240234375
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.495315551757812
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.58232879638672
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.7786865234375
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.12704086303711
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.1273193359375
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.321036338806152
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.11079978942871
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.571453094482422
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.023027420043945
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.981109619140625
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.212095260620117
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.21529197692871
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.331221580505371
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.066909790039062
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.184112548828125
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.654067993164062
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.985031127929688
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.469970703125
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.456573486328125
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.175369262695312
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.090696334838867
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.263498306274414
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.65839195251465
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.15217399597168
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 19.56679344177246
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.10873031616211
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.053505897521973
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.21860694885254
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.485485076904297
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.021175384521484
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.82667350769043
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.117908477783203
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.855022430419922
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.012800216674805
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.047908782958984
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.681955337524414
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.490158081054688
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.70611000061035
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.465560913085938
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.880937576293945
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.067625045776367
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.160350799560547
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.710338592529297
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.815542221069336
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.650827407836914
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 4,
            "error": 19.88987159729004
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.454225540161133
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.575332641601562
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.19434356689453
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.931346893310547
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.18756675720215
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.88904571533203
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.893095016479492
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.09556770324707
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.44484519958496
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.29458236694336
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.833982467651367
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.870882034301758
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.6223087310791
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.27488899230957
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.78739356994629
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.364145278930664
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.170547485351562
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.556163787841797
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.374780654907227
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.83559799194336
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.248004913330078
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.828462600708008
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.32436752319336
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.09926414489746
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.418075561523438
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.860618591308594
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.35036849975586
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.495033264160156
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.17833709716797
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.42033576965332
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.03838348388672
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.834545135498047
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.98610496520996
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.200485229492188
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.026018142700195
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.54572105407715
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.013833999633789
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.25230598449707
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.357454299926758
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.920305252075195
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.38445281982422
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.786954879760742
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.100183486938477
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.713741302490234
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.471302032470703
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.337568283081055
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.925432205200195
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.55490493774414
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.665903091430664
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.353139877319336
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.422616958618164
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.050116539001465
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.021743774414062
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.53070640563965
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 4,
            "error": 19.36370277404785
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.727790832519531
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.161191940307617
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.272964477539062
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 3,
            "error": 16.727781295776367
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.035120010375977
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.209657669067383
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.390726089477539
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.651399612426758
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.286474227905273
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.713985443115234
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.20174789428711
        },
        "lm_head": {
            "bit_width": 3,
            "error": 15.514396667480469
        }
    },
    "average_bit_width": 3.328888888888889,
    "error_threshold": 15,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.4868025392582693,
        "mmlu_results": {
            "overall_score": 0.43558282208588955,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.41,\"1\":0.57,\"2\":0.3492063492}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIn a world where technology had advanced to a point of near perfection, humanity had become complacent, relying on machines to solve all its problems. The air was clean, the land was fertile, and the people were content, but a little too content.\n\nIn a small village nestled between two great mountains, a young girl named Ava lived a simple life. She spent her days playing in the garden her grandfather tended, watching the plants grow and flourish under the careful care of the automated"
    }
}