{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "original_model_accuracy": 0.5299508376688463,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.698883056640625
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.999937057495117
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.402841567993164
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.578690528869629
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.307098388671875
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.805591583251953
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 21.56008529663086
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.0732479095459
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.553110122680664
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.669254302978516
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.192697525024414
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.02508544921875
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.50811195373535
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 37.33299255371094
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.737407684326172
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.44002342224121
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.715322494506836
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.419981002807617
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.604036331176758
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.95717430114746
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.365623474121094
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.234153747558594
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.16605567932129
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.967958450317383
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.794754028320312
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.463272094726562
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.142541885375977
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.06000518798828
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.410404205322266
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.338586807250977
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.976457595825195
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.90142822265625
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.651447296142578
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.325170516967773
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.82600212097168
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.229848861694336
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.286880493164062
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.11199951171875
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.994159698486328
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.74901008605957
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.467973709106445
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.8007869720459
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.26568603515625
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.8056640625
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.30699348449707
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.406246185302734
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.106087684631348
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.75735092163086
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.78472328186035
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.790157318115234
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.599239349365234
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.858522415161133
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.476978302001953
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.024694442749023
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.045703887939453
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.577829360961914
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.283504486083984
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.66196060180664
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.38970375061035
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.479984283447266
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.152408599853516
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.01289176940918
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.534196853637695
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.871610641479492
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.01842498779297
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.49198341369629
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.196197509765625
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.277700424194336
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.135364532470703
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.49788475036621
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.767881393432617
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.844715118408203
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.691068649291992
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.497173309326172
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.16748332977295
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.037830352783203
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.429988861083984
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.034011840820312
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.156356811523438
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.086299896240234
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.51099395751953
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.26740837097168
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.022428512573242
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.518310546875
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.462526321411133
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.707855224609375
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.08806037902832
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.575510025024414
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.470799446105957
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.270288467407227
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.732315063476562
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.361711502075195
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.665422439575195
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.18145751953125
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.77303123474121
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.8123779296875
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.255027770996094
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.433292388916016
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.552104949951172
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.121339797973633
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.06996726989746
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.448776245117188
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.98260498046875
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.89531707763672
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.453611373901367
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.656604766845703
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.289451599121094
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.020830154418945
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.55451202392578
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.101707458496094
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.849315643310547
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.607295989990234
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.61766815185547
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.451072692871094
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.26435661315918
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.626598358154297
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.379440307617188
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.568660736083984
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.60148811340332
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.72542953491211
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.645082473754883
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.932891845703125
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.773075103759766
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.429424285888672
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.52660369873047
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.55039405822754
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.003644943237305
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.626030921936035
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.100364685058594
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.94634246826172
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.92165756225586
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.308523178100586
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.575721740722656
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.198389053344727
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.708380699157715
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.02928352355957
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.04107093811035
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.525409698486328
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.16180992126465
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.69974136352539
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.56878662109375
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.162534713745117
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.973716735839844
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.78186798095703
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.2113037109375
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.108867645263672
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.555444717407227
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.610694885253906
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.524856567382812
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.23297691345215
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.086856842041016
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.220508575439453
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.136598587036133
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.687929153442383
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.765789985656738
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.139121055603027
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.669546127319336
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.35957908630371
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.738346099853516
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.9959716796875
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.680755615234375
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.002967834472656
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.41504955291748
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.682926177978516
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.28874969482422
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.392969131469727
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.87186050415039
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.764280319213867
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.037338256835938
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.586362838745117
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.71255874633789
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.69866943359375
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.05403709411621
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.817520141601562
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.634784698486328
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.663333892822266
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.220739364624023
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.99564552307129
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.728656768798828
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.126150131225586
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.77840805053711
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.533451080322266
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.53920841217041
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.16899299621582
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.545272827148438
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.95319366455078
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.574586868286133
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.864286422729492
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.48429298400879
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.923250198364258
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.434812545776367
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.818681716918945
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.456422805786133
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.020034790039062
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.090492248535156
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.67971420288086
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.148950576782227
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.759529113769531
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.668624877929688
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.185728073120117
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.648237228393555
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.836036682128906
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.93841552734375
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.958269119262695
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.799699783325195
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.96858787536621
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.72511863708496
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.01026725769043
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.548654556274414
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.122547149658203
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.139699935913086
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.109468460083008
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.883047103881836
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.775192260742188
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.598841667175293
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.444570541381836
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.026042938232422
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.799423217773438
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.69071388244629
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.67127799987793
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.38593292236328
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.641550064086914
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 2,
            "error": 17.593242645263672
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 2,
            "error": 15.485373497009277
        },
        "lm_head": {
            "bit_width": 3,
            "error": 18.821805953979492
        }
    },
    "average_bit_width": 2.6755555555555555,
    "error_threshold": 15,
    "min_quantile": 0.05,
    "max_quantile": 0.95,
    "quantized_model_accuracy": 0.48494105293303424
}