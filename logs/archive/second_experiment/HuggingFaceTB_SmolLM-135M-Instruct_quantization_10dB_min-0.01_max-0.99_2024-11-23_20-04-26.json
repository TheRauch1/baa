{
    "model_name": "HuggingFaceTB/SmolLM-135M-Instruct",
    "original_model_accuracy": 0.39463618573207615,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 10.042625427246094
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.642132759094238
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.443111419677734
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.584749221801758
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.458744049072266
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 13.283833503723145
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.240549087524414
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.779988288879395
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.363296508789062
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.963342666625977
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.458148002624512
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.054475784301758
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.926165580749512
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.650217056274414
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.06167221069336
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.908041954040527
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.57441520690918
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.66187572479248
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.824828147888184
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.555538177490234
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.423873901367188
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.714398384094238
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.823707580566406
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.486238479614258
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.708028793334961
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.468027114868164
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.41446304321289
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.744678497314453
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.96802806854248
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.900511741638184
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.760744094848633
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.06180191040039
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.949889183044434
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.455981254577637
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.724985122680664
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.794229507446289
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.186725616455078
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.233341217041016
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.461910247802734
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.91543960571289
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.591693878173828
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.943594932556152
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.775954246520996
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.386726379394531
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.032797813415527
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.712691307067871
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.807945251464844
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.568296432495117
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.96589469909668
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.057369232177734
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.909082412719727
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.850284576416016
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.852874755859375
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.922130584716797
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.597410202026367
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.942087173461914
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 3,
            "error": 12.894857406616211
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.830803871154785
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.037025451660156
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.739885330200195
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.960844993591309
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.588369369506836
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.310346603393555
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.623563766479492
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.607979774475098
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.603520393371582
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.256759643554688
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.667084693908691
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.645343780517578
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.057342529296875
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.440515518188477
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.472766876220703
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.492560386657715
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.932844161987305
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.683250427246094
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.508012771606445
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.8109130859375
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.909496307373047
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.025044441223145
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.221946716308594
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.807409286499023
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.132110595703125
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.661405563354492
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 32.185546875
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.288921356201172
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.109959602355957
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.069766998291016
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.7181396484375
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.207738876342773
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.073844909667969
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.946808815002441
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 11.962952613830566
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.166598320007324
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.836782455444336
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.94989013671875
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.8283052444458
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.672811508178711
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.821731567382812
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.199226379394531
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.810700416564941
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.381583213806152
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.53739070892334
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 14.594416618347168
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.601812362670898
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.437654495239258
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 12.059111595153809
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 16.20545768737793
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.111736297607422
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.198078155517578
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 14.827959060668945
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.562710762023926
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.486539840698242
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.321136474609375
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.498674392700195
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.754438400268555
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.549539566040039
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 14.632619857788086
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.632905960083008
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.465655326843262
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 3,
            "error": 11.783400535583496
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.410383224487305
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.218160629272461
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.894133567810059
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.092663764953613
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.767394065856934
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.572192192077637
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.468229293823242
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.322502136230469
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.816863059997559
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.555011749267578
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.126228332519531
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.665945053100586
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.42160415649414
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 3,
            "error": 12.746306419372559
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.89664363861084
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.873756408691406
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.762813568115234
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.472859382629395
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.784077644348145
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.484419822692871
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 12.253442764282227
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.522136688232422
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.323417663574219
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.875734329223633
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.65732479095459
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.029890060424805
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.706336975097656
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.267438888549805
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.001740455627441
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.191177368164062
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.422494888305664
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.594749450683594
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.175886154174805
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.013766288757324
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.385396003723145
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.662793159484863
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.216094970703125
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.609753608703613
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.287267684936523
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.889721870422363
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.934114456176758
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.026261329650879
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.163034439086914
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.456607818603516
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.078156471252441
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.00731372833252
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.76999282836914
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.842327117919922
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.009546279907227
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.087289810180664
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.907504081726074
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.342395782470703
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 14.915136337280273
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.884556770324707
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.78864574432373
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.67014217376709
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.450546264648438
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.725972175598145
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.21190071105957
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.24636173248291
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.795432090759277
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.748004913330078
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.040109634399414
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.90114688873291
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.703702926635742
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.998407363891602
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.122617721557617
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.91649055480957
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.373740196228027
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.446732521057129
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 16.572898864746094
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.231109619140625
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.153130531311035
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 15.055410385131836
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.786853790283203
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.66413402557373
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.014883995056152
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 3,
            "error": 16.41695213317871
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.185203552246094
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.68699836730957
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.2916202545166
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.515800476074219
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 2,
            "error": 21.61748504638672
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 3,
            "error": 12.745607376098633
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 3,
            "error": 12.873440742492676
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.372363090515137
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.850221633911133
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 3,
            "error": 13.951567649841309
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.327056884765625
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.3210391998291
        },
        "lm_head": {
            "bit_width": 2,
            "error": 11.475921630859375
        }
    },
    "average_bit_width": 2.914691943127962,
    "error_threshold": 10,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_accuracy": 0.27766411670521257
}