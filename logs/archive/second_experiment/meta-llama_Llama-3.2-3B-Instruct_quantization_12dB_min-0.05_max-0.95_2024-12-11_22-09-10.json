{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "original_model_benchmarks": {
        "wikitext_accuracy": 0.4633191733091499,
        "mmlu_results": {
            "overall_score": 0.4570552147239264,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.53,\"1\":0.53,\"2\":0.3412698413}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nOnce upon a time, in a world ravaged by climate change, wars, and social inequality, humanity teetered on the brink of collapse. The once blue skies were now a permanent gray, the oceans were choked with plastic, and the air was thick with pollution.\n\nBut amidst the chaos, a small group of individuals from different walks of life came together to form a community that would change the course of history.\n\nAva, a brilliant scientist, had dedicated her life to"
    },
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.668914794921875
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.100831985473633
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.34484100341797
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.381153106689453
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.355247497558594
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.54828453063965
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.498245239257812
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.0415096282959
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.838247299194336
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.238906860351562
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.37625503540039
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.860940933227539
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.967605590820312
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 28.024322509765625
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.729896545410156
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.734745025634766
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.40784454345703
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.121204376220703
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.206496238708496
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.851980209350586
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.245485305786133
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.383769989013672
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.63238525390625
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.411563873291016
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.549638748168945
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.892654418945312
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.943023681640625
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.815540313720703
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.859718322753906
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.911052703857422
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.737598419189453
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.877519607543945
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.263997077941895
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.028728485107422
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.85233497619629
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.659852981567383
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.836383819580078
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.144405364990234
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.87818717956543
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.614945411682129
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.175437927246094
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.932979583740234
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.696578979492188
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.512866973876953
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.205253601074219
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.54570770263672
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.328673362731934
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.420326232910156
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.90178108215332
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.177305221557617
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.324682235717773
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.730472564697266
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.872955322265625
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.400144577026367
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.824987411499023
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.642475128173828
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.001293182373047
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.091175079345703
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.426342010498047
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.09697437286377
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.516419410705566
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.860641479492188
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.66594696044922
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.712020874023438
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.620174407958984
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.419877052307129
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.089576721191406
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.638947486877441
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.90203285217285
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.615446090698242
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.586387634277344
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.425899505615234
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.141860961914062
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.730029106140137
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.773663520812988
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.080514907836914
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.588016510009766
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.816455841064453
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.18148422241211
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.21692180633545
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.03010368347168
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.643839836120605
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.143739700317383
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.779619216918945
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.412084579467773
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.304672241210938
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.553333282470703
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.458133697509766
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.883052825927734
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.001676559448242
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.539331436157227
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.077550888061523
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.797080993652344
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.071359634399414
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.248357772827148
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.124202728271484
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.542455673217773
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.594730377197266
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.173837661743164
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.742101669311523
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.346330642700195
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.617178916931152
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.09781837463379
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.46240997314453
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.846410751342773
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.74188232421875
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.820282936096191
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.357711791992188
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.396154403686523
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.656463623046875
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.359420776367188
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.691150665283203
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.41033363342285
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.643608093261719
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.500747680664062
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.071487426757812
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.573795318603516
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.135887145996094
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.58647346496582
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.383243560791016
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.916214942932129
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.475648880004883
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.34355354309082
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.305628776550293
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.006999969482422
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.657424926757812
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.855281829833984
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.36960220336914
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.539945602416992
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.509862899780273
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.066084861755371
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.00560188293457
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.490497589111328
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.117935180664062
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.866554260253906
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.288803100585938
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.499858856201172
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.067508697509766
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.133756637573242
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.74460220336914
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.21350860595703
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.444406509399414
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.680347442626953
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.038328170776367
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.34961986541748
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.922279357910156
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.709423065185547
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.52978515625
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.744754791259766
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.746612548828125
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.887052536010742
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.905885696411133
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.876243591308594
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.521644592285156
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.42511749267578
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.151391983032227
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.058828353881836
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.290145874023438
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.086751937866211
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.8200740814209
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.467742919921875
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.729387283325195
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.360651016235352
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.364376068115234
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.234737396240234
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.833898544311523
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.038949966430664
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.41927146911621
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.876213073730469
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.678620338439941
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.76869010925293
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.87042236328125
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.224004745483398
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.446918487548828
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.058805465698242
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.812711715698242
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.556236267089844
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.952041625976562
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.924205780029297
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.812040328979492
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.417679786682129
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.969970703125
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.342336654663086
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.011491775512695
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.192062377929688
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.33753776550293
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.101816177368164
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.002028465270996
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.954622268676758
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.64893341064453
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.616140365600586
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.18941879272461
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.41215705871582
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.932882308959961
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 2,
            "error": 17.496665954589844
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 2,
            "error": 14.898544311523438
        },
        "lm_head": {
            "bit_width": 2,
            "error": 14.314414024353027
        }
    },
    "average_bit_width": 2.487309644670051,
    "error_threshold": 12,
    "min_quantile": 0.05,
    "max_quantile": 0.95,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.3901961720204286,
        "mmlu_results": {
            "overall_score": 0.22392638036809817,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.24,\"1\":0.26,\"2\":0.1825396825}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIt was a chilly winter evening in a small, coastal town where the sea met the sky. The sun was setting over the ocean, painting the horizon with hues of orange, pink, and purple. The residents of this town were no strangers to hardship and struggle, having faced the harsh realities of poverty, illness, and loss.\n\nIn the midst of this bleakness, there lived a young woman named Maria, who had lost her mother at a tender age and her father to a"
    }
}