{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "original_model_accuracy": 0.5299508376688463,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.87803840637207
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.38760757446289
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 4,
            "error": 15.883613586425781
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 5,
            "error": 15.108332633972168
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 5,
            "error": 20.881427764892578
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.29874038696289
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 6,
            "error": 20.171009063720703
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 16.590879440307617
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.973087310791016
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.410804748535156
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 5,
            "error": 16.69537353515625
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 5,
            "error": 20.675657272338867
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.72291374206543
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 8,
            "error": 19.265796661376953
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.11713218688965
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.638447761535645
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.43838882446289
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.358821868896484
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.263416290283203
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.134681701660156
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.574012756347656
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 3,
            "error": 16.5981502532959
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.129844665527344
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.824966430664062
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.857494354248047
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.509845733642578
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.158197402954102
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.578309059143066
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.30109405517578
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.283893585205078
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.781166076660156
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.768884658813477
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.80661392211914
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.79080581665039
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.52625846862793
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.840089797973633
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.314332962036133
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.504270553588867
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.05611228942871
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.44733428955078
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.111042022705078
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.775033950805664
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.103010177612305
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.648971557617188
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.580638885498047
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.725975036621094
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.851369857788086
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.213545799255371
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.04662322998047
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.857160568237305
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.9348201751709
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.925748825073242
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.65819549560547
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.673595428466797
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.161184310913086
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.911645889282227
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 4,
            "error": 18.252986907958984
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.478612899780273
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.197153091430664
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 5,
            "error": 17.53807830810547
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.831682205200195
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.151317596435547
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.88886070251465
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.802764892578125
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.10784912109375
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.151668548583984
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 5,
            "error": 17.725893020629883
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.562400817871094
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.125497817993164
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.89409828186035
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 4,
            "error": 18.587549209594727
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.65857696533203
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.489925384521484
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 5,
            "error": 17.553550720214844
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.76401138305664
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.429506301879883
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.636262893676758
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.64105224609375
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.248931884765625
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.430072784423828
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 5,
            "error": 16.708263397216797
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.026811599731445
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.199752807617188
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.8651123046875
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.381126403808594
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.850648880004883
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.735721588134766
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 5,
            "error": 16.319862365722656
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.34157943725586
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.754671096801758
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 5,
            "error": 19.641952514648438
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.517030715942383
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.88791847229004
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.250228881835938
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 5,
            "error": 16.517539978027344
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.521797180175781
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.956546783447266
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.58548355102539
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.386680603027344
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.63606834411621
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.86020278930664
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.231178283691406
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.172536849975586
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.80154800415039
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.456840515136719
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 4,
            "error": 18.781524658203125
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.91909408569336
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.76785659790039
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 5,
            "error": 17.69300079345703
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.961490631103516
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.1903018951416
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.387489318847656
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 4,
            "error": 18.809377670288086
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.257278442382812
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.44626235961914
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 5,
            "error": 17.947357177734375
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.430179595947266
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.314718246459961
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 5,
            "error": 18.310415267944336
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.085622787475586
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.669971466064453
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.048738479614258
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.386451721191406
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.635700225830078
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.362530708312988
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 5,
            "error": 16.65380096435547
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.77492904663086
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.972097396850586
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.074338912963867
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.74848175048828
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.35700798034668
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.918379783630371
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 5,
            "error": 16.039793014526367
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.5645694732666
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.662147521972656
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.217227935791016
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.688941955566406
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.898713111877441
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.665139198303223
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 5,
            "error": 16.377033233642578
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.266202926635742
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.02155113220215
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.848718643188477
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.092742919921875
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.083213806152344
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.773578643798828
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.01413345336914
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.767440795898438
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.968263626098633
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.579620361328125
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 5,
            "error": 16.26128578186035
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.086544036865234
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.753173828125
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 5,
            "error": 19.813875198364258
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.411632537841797
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.01297378540039
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.994403839111328
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.147809982299805
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.170574188232422
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.95451831817627
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.273286819458008
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.555652618408203
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.397171020507812
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.140047073364258
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.0943603515625
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.990704536437988
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.744938850402832
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.014047622680664
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.282690048217773
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.700538635253906
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.843822479248047
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 5,
            "error": 21.101177215576172
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.719167709350586
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.629129409790039
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.637910842895508
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.996978759765625
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.971729278564453
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.045785903930664
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.65520477294922
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.58857536315918
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.517548561096191
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 5,
            "error": 18.349201202392578
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.01453399658203
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.950611114501953
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.064319610595703
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.084972381591797
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.685522079467773
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.724796295166016
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 5,
            "error": 19.96440315246582
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.313032150268555
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.728511810302734
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.173784255981445
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.748777389526367
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.33313751220703
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.008203506469727
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.29409408569336
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.40096664428711
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.182300567626953
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.4366512298584
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.831871032714844
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.439258575439453
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.792840957641602
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.10643482208252
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.78154182434082
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.248717308044434
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.162546157836914
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 5,
            "error": 21.085451126098633
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.510828018188477
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.917606353759766
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 5,
            "error": 19.228723526000977
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.907039642333984
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.0284423828125
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 4,
            "error": 15.695999145507812
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.315312385559082
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.903675079345703
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 4,
            "error": 18.399330139160156
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.374357223510742
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.54478645324707
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 3,
            "error": 16.533185958862305
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.29631233215332
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 5,
            "error": 16.89627456665039
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 4,
            "error": 19.949934005737305
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 4,
            "error": 19.708192825317383
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 5,
            "error": 15.871495246887207
        },
        "lm_head": {
            "bit_width": 5,
            "error": 20.55316162109375
        }
    },
    "average_bit_width": 4.257777777777778,
    "error_threshold": 15,
    "min_quantile": 0,
    "max_quantile": 1,
    "quantized_model_accuracy": 0.471433344470431
}