{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "original_model_accuracy": 0.4633191733091499,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 24.707414627075195
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 23.02828598022461
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.886882781982422
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.750031471252441
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.920150756835938
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.76336669921875
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 15.795641899108887
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 24.642452239990234
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 22.79181671142578
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.64590835571289
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.691009521484375
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.093637466430664
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.157001495361328
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 30.2957820892334
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.66327667236328
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.536100387573242
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.72249984741211
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.446605682373047
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.783082962036133
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.040420532226562
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.483610153198242
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.984699249267578
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.27556037902832
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.730724334716797
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.756948471069336
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.124987602233887
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.155071258544922
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.053783416748047
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 22.58622169494629
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.539011001586914
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.091896057128906
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.07341766357422
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.51506805419922
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.232751846313477
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.09395980834961
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.262439727783203
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.444015502929688
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.465490341186523
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.14673614501953
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.865087509155273
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.37909507751465
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.173370361328125
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.379716873168945
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.006797790527344
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.803977966308594
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.80112075805664
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.623641967773438
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.63884925842285
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.134737014770508
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.815338134765625
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.83721923828125
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 2,
            "error": 15.071794509887695
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.132911682128906
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.709508895874023
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.060165405273438
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.90567970275879
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.657747268676758
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.007526397705078
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.139869689941406
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.313831329345703
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.818511962890625
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.12832260131836
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.9447021484375
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.437583923339844
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.499954223632812
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.177825927734375
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.406579971313477
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.008148193359375
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.131601333618164
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.849027633666992
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.261201858520508
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.364416122436523
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 2,
            "error": 15.449529647827148
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.131256103515625
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.155179977416992
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.344097137451172
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.88662338256836
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.31425666809082
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.600170135498047
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.811426162719727
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.3834228515625
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.036245346069336
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.40739631652832
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.07024383544922
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.18484878540039
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.44542694091797
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.243305206298828
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.78230857849121
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.281936645507812
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.305282592773438
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.811933517456055
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.690515518188477
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.903274536132812
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.89136505126953
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.571985244750977
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.561782836914062
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.83849334716797
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.835689544677734
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.05712127685547
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.64604377746582
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.842458724975586
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.833965301513672
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.46462059020996
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.724437713623047
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.096515655517578
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.409912109375
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.728370666503906
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.719308853149414
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.640949249267578
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.047813415527344
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.601348876953125
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.934188842773438
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.036548614501953
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.51760482788086
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.086833953857422
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.27952766418457
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.879852294921875
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.343687057495117
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.787338256835938
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.05687141418457
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.60700035095215
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.88998031616211
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.555152893066406
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.622394561767578
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.22003936767578
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.876192092895508
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.635217666625977
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.43523406982422
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.02994155883789
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.747289657592773
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.36203384399414
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.220735549926758
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.701129913330078
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.800779342651367
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.79030990600586
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.890369415283203
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.73411750793457
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.32271957397461
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.324188232421875
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.976757049560547
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.95611000061035
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.414955139160156
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.15410614013672
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.26873779296875
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.608920097351074
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.105344772338867
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.931686401367188
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.205604553222656
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.7315616607666
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.368309020996094
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.102657318115234
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.176405906677246
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.063594818115234
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.718017578125
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.18813133239746
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.18705940246582
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.631580352783203
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.503538131713867
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.369331359863281
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.005929946899414
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.673179626464844
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.422618865966797
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.20736312866211
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.78636932373047
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.496185302734375
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.168827056884766
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.2424259185791
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.636627197265625
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.631288528442383
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.597091674804688
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.714807510375977
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.008878707885742
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.59513282775879
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.66789436340332
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.284406661987305
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.684783935546875
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.24547004699707
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.288240432739258
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.169158935546875
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.21575927734375
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 22.00375747680664
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.202062606811523
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.152164459228516
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.39505386352539
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.06665802001953
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.543895721435547
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.651145935058594
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 2,
            "error": 16.20425796508789
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 21.189510345458984
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.140209197998047
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.27611541748047
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.016136169433594
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 22.029993057250977
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.464508056640625
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 2,
            "error": 19.755857467651367
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 2,
            "error": 17.178844451904297
        },
        "lm_head": {
            "bit_width": 2,
            "error": 16.464946746826172
        }
    },
    "average_bit_width": 2.5380710659898478,
    "error_threshold": 15,
    "min_quantile": 0.1,
    "max_quantile": 0.9,
    "quantized_model_accuracy": 0.4370674430814758
}