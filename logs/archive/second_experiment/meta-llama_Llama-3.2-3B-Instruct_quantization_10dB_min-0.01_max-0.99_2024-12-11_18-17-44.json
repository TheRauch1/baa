{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "original_model_benchmarks": {
        "wikitext_accuracy": 0.4633191733091499,
        "mmlu_results": {
            "overall_score": 0.4570552147239264,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.53,\"1\":0.53,\"2\":0.3412698413}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nOnce upon a time, in a world ravaged by climate change, wars, and social inequality, humanity teetered on the brink of collapse. The once blue skies were now a permanent gray, the oceans were choked with plastic, and the air was thick with pollution.\n\nBut amidst the chaos, a small group of individuals from different walks of life came together to form a community that would change the course of history.\n\nAva, a brilliant scientist, had dedicated her life to"
    },
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.203710556030273
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.035258293151855
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.512253761291504
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.787277221679688
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.518924713134766
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.401253700256348
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 16.927936553955078
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.24036979675293
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.416561126708984
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.627248764038086
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.664584159851074
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.694574356079102
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.852869033813477
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 24.396812438964844
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.955164909362793
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.033899307250977
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.890523910522461
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.623329162597656
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.417068481445312
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.78868293762207
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.62277603149414
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.2813720703125
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.259513854980469
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.123194694519043
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.333720207214355
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.040250778198242
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.859996795654297
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.515560150146484
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.079011917114258
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.191722869873047
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.233696937561035
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.553628921508789
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.044635772705078
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.879865646362305
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.69727611541748
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.021673202514648
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.84024715423584
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.655841827392578
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.749910354614258
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.374969482421875
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.01678466796875
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.643112182617188
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.360719680786133
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.177068710327148
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.299360275268555
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.322649955749512
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.049177169799805
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.255599975585938
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.734077453613281
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.89382553100586
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.758878707885742
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.75379180908203
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.670318603515625
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.014822006225586
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.60335636138916
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.499043464660645
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.585343360900879
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.274279594421387
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.381011962890625
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.93130874633789
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.071767807006836
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.647235870361328
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.479779243469238
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.357477188110352
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.696065902709961
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.023269653320312
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.81014633178711
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.213071823120117
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.666149139404297
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.42071533203125
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.462532997131348
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.586747169494629
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.061838150024414
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.438865661621094
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.29769229888916
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.789061546325684
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.317771911621094
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.970157623291016
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.029040336608887
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.304832458496094
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.845561981201172
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.044954299926758
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.772464752197266
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.562865257263184
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.16515064239502
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.356724739074707
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.268798828125
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.275604248046875
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.3152437210083
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.651815414428711
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.315177917480469
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.888092041015625
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.539639472961426
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.45936107635498
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.05154037475586
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.333723068237305
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.117069244384766
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.430161476135254
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.415855407714844
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.363115310668945
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.741943359375
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.487747192382812
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.408077239990234
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.103721618652344
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.683408737182617
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.513370513916016
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.140275001525879
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.853801727294922
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.28085708618164
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.025787353515625
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.068405151367188
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.520248413085938
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.416425704956055
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.955047607421875
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.71045970916748
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.998405456542969
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.108404159545898
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.94721508026123
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.46625804901123
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.37973403930664
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.158620834350586
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.91690444946289
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.233590126037598
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.877866744995117
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.874364852905273
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.556024551391602
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.624159812927246
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.460563659667969
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.673368453979492
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.2979097366333
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.66914176940918
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.92581558227539
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.386673927307129
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.634984970092773
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.000179290771484
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.338857650756836
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.135080337524414
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.65524673461914
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.040446281433105
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.571826934814453
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.259828567504883
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.476953506469727
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.283951759338379
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.948102951049805
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.339324951171875
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.866328239440918
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.637945175170898
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.161445617675781
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.582842826843262
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.045927047729492
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.760562896728516
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.919456481933594
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.840272903442383
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.422831535339355
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.000274658203125
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.685731887817383
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.327980041503906
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.047195434570312
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.0241756439209
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.769876480102539
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.3501558303833
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.556228637695312
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.614310264587402
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.68432903289795
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.181977272033691
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.260913848876953
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.990230560302734
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.342735290527344
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.675172805786133
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.31523609161377
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.660585403442383
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.768943786621094
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.49959945678711
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.376382827758789
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.993480682373047
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 10.85817813873291
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.719467163085938
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.014537811279297
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.812515258789062
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.814109802246094
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.691619873046875
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.893479347229004
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.989127159118652
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.019186973571777
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.064760208129883
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.147140502929688
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.088428497314453
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.82322883605957
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.806384086608887
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.95605754852295
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.83544921875
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.762027740478516
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.214263916015625
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.660409927368164
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.217024803161621
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 2,
            "error": 11.151344299316406
        },
        "lm_head": {
            "bit_width": 2,
            "error": 11.172447204589844
        }
    },
    "average_bit_width": 2.5786802030456855,
    "error_threshold": 10,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.17641162712996994,
        "mmlu_results": {
            "overall_score": 0.27300613496932513,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.28,\"1\":0.32,\"2\":0.2301587302}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIn a small, yet thriving village, there was a 5-year-old girl. She had a 1-year-old brother and a 2-year-old sister. The girl had a 1-year-old brother and a 2-year-old sister. The girl had a 1-year-old brother and a 3-year-old brother. The girl had a 1-year-old brother and a 2-year-old sister. The girl had a 1-year-old brother and a "
    }
}