{
    "model_name": "HuggingFaceTB/SmolLM-135M-Instruct",
    "original_model_accuracy": 0.39463618573207615,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.373939514160156
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.3605375289917
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 2,
            "error": 15.3724946975708
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 20.5768985748291
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.893775939941406
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.855226516723633
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 16.831268310546875
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.391704559326172
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.223272323608398
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.359293937683105
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 2,
            "error": 16.927473068237305
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.289915084838867
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.014991760253906
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.811958312988281
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.376880645751953
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.398528099060059
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.136415481567383
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.90179443359375
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.008052825927734
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.709871292114258
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.549299240112305
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.104869842529297
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.036123275756836
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.88118553161621
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.81707191467285
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.583492279052734
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.52782440185547
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.80729103088379
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.53264045715332
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.833192825317383
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.312664031982422
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.25850486755371
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.1690616607666
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.491016387939453
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.755229949951172
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.562518119812012
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.335124015808105
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.343263626098633
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.462846755981445
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.040691375732422
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.64004898071289
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.97333526611328
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.35706901550293
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.258339881896973
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.296981811523438
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.758996963500977
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.950883865356445
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.671607971191406
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.993404388427734
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.023477554321289
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.67090606689453
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.785049438476562
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.94251251220703
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.012228012084961
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.92845916748047
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.97315788269043
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.326528549194336
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.554595947265625
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.425329208374023
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.829471588134766
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.097859382629395
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.824399948120117
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.39504051208496
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.000883102416992
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.80982208251953
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.111462593078613
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.48196029663086
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.158538818359375
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.8354549407959
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.13308334350586
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.087706565856934
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.84365463256836
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.399253845214844
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.991178512573242
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.759872436523438
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.869678497314453
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.88770866394043
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.254846572875977
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.79024887084961
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.218687057495117
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.851211547851562
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.342581748962402
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.01696014404297
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 36.454280853271484
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.762421607971191
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.560359954833984
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.6412353515625
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.737812042236328
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.112648010253906
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.164155960083008
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 2,
            "error": 14.156511306762695
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.031150817871094
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.468504905700684
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.151326179504395
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.334877014160156
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.220282554626465
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.256269454956055
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.050127029418945
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.535921096801758
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.559842109680176
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.815855979919434
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.815153121948242
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.900136947631836
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.293869018554688
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.77529525756836
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.594304084777832
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.295305252075195
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.3940372467041
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.337886810302734
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.886512756347656
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.126279830932617
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.761966705322266
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.826037406921387
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.453022003173828
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.652362823486328
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.66875457763672
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.036266326904297
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.11145782470703
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.661020278930664
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.42739200592041
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.949028968811035
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.422863006591797
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.14602279663086
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.03257179260254
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.181215286254883
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.723148345947266
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.165334701538086
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.133330345153809
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.4529972076416
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.756507873535156
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.23509407043457
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.173355102539062
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.699085235595703
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.639253616333008
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.804771423339844
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.835420608520508
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.16633415222168
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.074875831604004
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.194700241088867
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.57221031188965
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.474295616149902
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.54683780670166
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.06923484802246
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.110214233398438
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.102383613586426
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.349884033203125
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.837745666503906
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.488149642944336
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.276411056518555
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.186843872070312
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.49305534362793
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.111871719360352
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.61582374572754
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.129638671875
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.967906951904297
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.977761268615723
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.890886306762695
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.657175064086914
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.028839111328125
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.186824798583984
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.050321578979492
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.775997161865234
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.582355499267578
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.073139190673828
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.077242851257324
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.83985137939453
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.049829483032227
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.89662742614746
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.211471557617188
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.785263061523438
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.284130096435547
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.461390495300293
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.568099975585938
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.19301986694336
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.769561767578125
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.418729782104492
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.286761283874512
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.73775863647461
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.984416007995605
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.580774307250977
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.048954010009766
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.752429962158203
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.939369201660156
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.763876914978027
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.702369689941406
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 2,
            "error": 18.21031951904297
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.55369758605957
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.159502029418945
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.419200897216797
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.892007827758789
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.786190032958984
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.44927406311035
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.07368278503418
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.48128890991211
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.13868522644043
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.765708923339844
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.351764678955078
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.664606094360352
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.251588821411133
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.425824165344238
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.60647964477539
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.01298713684082
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 2,
            "error": 24.73928451538086
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.093157768249512
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.947978019714355
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.40835952758789
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.750711441040039
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.950870513916016
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.731510162353516
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 2,
            "error": 15.362476348876953
        },
        "lm_head": {
            "bit_width": 2,
            "error": 14.328664779663086
        }
    },
    "average_bit_width": 2.5829383886255926,
    "error_threshold": 12,
    "min_quantile": 0.05,
    "max_quantile": 0.95
}