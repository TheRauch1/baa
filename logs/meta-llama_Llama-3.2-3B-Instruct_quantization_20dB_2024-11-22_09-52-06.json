{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "original_model_accuracy": 0.4633191733091499,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.661603927612305
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.797466278076172
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.098392486572266
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.24347686767578
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.754138946533203
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.37881088256836
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 6,
            "error": 23.917314529418945
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 4,
            "error": 24.73940086364746
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.980998992919922
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 5,
            "error": 24.17259407043457
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 6,
            "error": 23.883726119995117
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 5,
            "error": 23.026206970214844
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.80549430847168
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 8,
            "error": 21.62992286682129
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.52965545654297
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 5,
            "error": 26.334259033203125
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.552515029907227
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.035259246826172
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.871484756469727
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.468780517578125
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 6,
            "error": 25.204856872558594
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 4,
            "error": 23.995914459228516
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.641773223876953
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.99696159362793
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.726613998413086
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.950214385986328
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.814590454101562
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 5,
            "error": 22.015657424926758
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.69088363647461
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 4,
            "error": 23.740962982177734
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.836772918701172
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 6,
            "error": 26.075105667114258
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 5,
            "error": 24.632373809814453
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.125499725341797
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 5,
            "error": 22.483821868896484
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.386945724487305
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.517356872558594
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 5,
            "error": 24.12802505493164
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.877140045166016
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 5,
            "error": 25.16500473022461
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.307172775268555
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.172042846679688
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.867542266845703
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.086610794067383
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 5,
            "error": 25.09610366821289
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 6,
            "error": 26.022228240966797
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 5,
            "error": 25.26238441467285
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.794158935546875
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.920421600341797
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 4,
            "error": 23.620121002197266
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.575000762939453
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 5,
            "error": 25.68630027770996
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 6,
            "error": 26.037288665771484
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 5,
            "error": 25.4243106842041
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.86580467224121
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.541261672973633
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.374814987182617
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.438739776611328
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 5,
            "error": 24.713340759277344
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.88306427001953
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 5,
            "error": 25.29221534729004
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.014862060546875
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.38460350036621
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.3814754486084
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.70798110961914
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 5,
            "error": 24.35540008544922
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.985733032226562
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 5,
            "error": 24.743059158325195
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.306140899658203
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.27157211303711
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.48117446899414
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.72260284423828
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 5,
            "error": 25.659208297729492
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.160022735595703
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 5,
            "error": 24.0658016204834
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.177623748779297
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.375484466552734
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 4,
            "error": 23.421106338500977
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.798324584960938
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 5,
            "error": 25.2083740234375
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.99782371520996
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 5,
            "error": 23.497812271118164
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.288402557373047
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.317380905151367
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.22210693359375
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.88005828857422
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 5,
            "error": 24.512083053588867
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 6,
            "error": 23.497020721435547
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.417034149169922
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.266891479492188
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.327516555786133
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.30354118347168
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.60590934753418
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.694055557250977
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.37171173095703
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.01051902770996
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.239757537841797
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.91180419921875
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.728914260864258
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.80109405517578
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.567829132080078
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.379661560058594
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.15968894958496
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.5703125
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.777847290039062
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.277936935424805
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.301036834716797
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.955730438232422
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.38237762451172
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.854116439819336
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.17656135559082
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 6,
            "error": 24.6363468170166
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.19192123413086
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.117782592773438
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.416318893432617
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.754241943359375
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.317562103271484
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.360553741455078
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.318347930908203
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.113008499145508
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.65283203125
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.952564239501953
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 6,
            "error": 26.047195434570312
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.330121994018555
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.44681167602539
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 6,
            "error": 24.087284088134766
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.429180145263672
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.180034637451172
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.316009521484375
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.16034698486328
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.33600425720215
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.35929298400879
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 5,
            "error": 22.30169105529785
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.583133697509766
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.891189575195312
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.99842643737793
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 6,
            "error": 23.696060180664062
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.906660079956055
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.022411346435547
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.53909683227539
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.517942428588867
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.143707275390625
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.538410186767578
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.80685806274414
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.331933975219727
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.579364776611328
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.450275421142578
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.045297622680664
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 5,
            "error": 26.013046264648438
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.132537841796875
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 5,
            "error": 21.642616271972656
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.748580932617188
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.320858001708984
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 5,
            "error": 22.401411056518555
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.23061180114746
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.05580711364746
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.382966995239258
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.32231903076172
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.929439544677734
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.431270599365234
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 6,
            "error": 26.505809783935547
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.176055908203125
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 5,
            "error": 26.03232192993164
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.353919982910156
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.481266021728516
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.224231719970703
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.80707359313965
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.989097595214844
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.1785831451416
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 5,
            "error": 25.973913192749023
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.49172592163086
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 5,
            "error": 22.078907012939453
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.93199348449707
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.90943145751953
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 5,
            "error": 23.17233657836914
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.461971282958984
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.14107894897461
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.730304718017578
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 5,
            "error": 21.011240005493164
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 5,
            "error": 23.123043060302734
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 5,
            "error": 23.524356842041016
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 5,
            "error": 22.208253860473633
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.249128341674805
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 5,
            "error": 26.145732879638672
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 5,
            "error": 21.875659942626953
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.91132164001465
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 5,
            "error": 23.669536590576172
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 5,
            "error": 25.176803588867188
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.571300506591797
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 4,
            "error": 22.741947174072266
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.54312515258789
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 5,
            "error": 21.616371154785156
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 6,
            "error": 22.513322830200195
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.805858612060547
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 5,
            "error": 23.560068130493164
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 6,
            "error": 25.337623596191406
        },
        "lm_head": {
            "bit_width": 5,
            "error": 25.3481502532959
        }
    },
    "average_bit_width": 4.913705583756345,
    "error_threshold": 20,
    "min_quantile": 0.0,
    "max_quantile": 1.0
}