{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "original_model_benchmarks": {
        "wikitext_accuracy": 0.4633191733091499,
        "mmlu_results": {
            "overall_score": 0.4570552147239264,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.53,\"1\":0.53,\"2\":0.3412698413}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nOnce upon a time, in a world ravaged by climate change, wars, and social inequality, humanity teetered on the brink of collapse. The once blue skies were now a permanent gray, the oceans were choked with plastic, and the air was thick with pollution.\n\nBut amidst the chaos, a small group of individuals from different walks of life came together to form a community that would change the course of history.\n\nAva, a brilliant scientist, had dedicated her life to"
    },
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.203710556030273
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.035258293151855
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.512253761291504
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.787277221679688
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.518924713134766
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.401253700256348
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 16.927936553955078
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.24036979675293
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.416561126708984
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.627248764038086
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.664584159851074
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.070560455322266
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.852869033813477
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 24.396812438964844
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.955164909362793
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.234134674072266
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.890523910522461
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.623329162597656
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.417068481445312
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.78868293762207
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.62277603149414
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.2813720703125
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.259513854980469
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.123194694519043
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.333720207214355
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.040250778198242
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.859996795654297
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.515560150146484
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.079011917114258
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.191722869873047
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.233696937561035
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.553628921508789
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.390785217285156
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.879865646362305
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.69727611541748
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.021673202514648
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.84024715423584
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.655841827392578
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.749910354614258
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.719579696655273
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.01678466796875
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.643112182617188
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.360719680786133
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.177068710327148
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.299360275268555
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.322649955749512
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.049177169799805
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.255599975585938
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.734077453613281
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.89382553100586
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.758878707885742
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.75379180908203
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.670318603515625
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.014822006225586
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.60335636138916
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.499043464660645
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.585343360900879
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.274279594421387
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.381011962890625
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.53350830078125
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.071767807006836
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.647235870361328
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.479779243469238
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.357477188110352
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.696065902709961
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.023269653320312
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.491596221923828
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.213071823120117
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.666149139404297
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.42071533203125
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.462532997131348
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.586747169494629
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.061838150024414
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.022409439086914
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.29769229888916
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.789061546325684
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.317771911621094
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.970157623291016
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.029040336608887
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.304832458496094
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.845561981201172
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.044954299926758
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.772464752197266
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.562865257263184
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.16515064239502
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.75629234313965
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.268798828125
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.923095703125
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.3152437210083
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.651815414428711
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.315177917480469
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.888092041015625
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.826581954956055
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.45936107635498
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.05154037475586
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.333723068237305
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.117069244384766
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.430161476135254
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.415855407714844
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.363115310668945
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.741943359375
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.487747192382812
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.408077239990234
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.103721618652344
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.683408737182617
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.513370513916016
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.5108699798584
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.853801727294922
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.28085708618164
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.025787353515625
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.068405151367188
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.520248413085938
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.416425704956055
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.542991638183594
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.71045970916748
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.998405456542969
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.451953887939453
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.94721508026123
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.46625804901123
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.37973403930664
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.711870193481445
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.91690444946289
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.233590126037598
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.223125457763672
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.874364852905273
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.556024551391602
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.791921615600586
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.121557235717773
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.673368453979492
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.2979097366333
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.010852813720703
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.92581558227539
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.386673927307129
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.634984970092773
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.750286102294922
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.338857650756836
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.135080337524414
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.00496482849121
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.040446281433105
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.571826934814453
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.259828567504883
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.034778594970703
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.283951759338379
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.948102951049805
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.339324951171875
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.866328239440918
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.637945175170898
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.161445617675781
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.993953704833984
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.045927047729492
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.760562896728516
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.919456481933594
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.840272903442383
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.422831535339355
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.000274658203125
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.57339859008789
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.327980041503906
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.047195434570312
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.0241756439209
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.769876480102539
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.3501558303833
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.752384185791016
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.977277755737305
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.68432903289795
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.181977272033691
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.585186004638672
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.990230560302734
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.342735290527344
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.011873245239258
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.986957550048828
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.660585403442383
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.768943786621094
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.826751708984375
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.376382827758789
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.993480682373047
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.364465713500977
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.471498489379883
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.014537811279297
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.812515258789062
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.110441207885742
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.691619873046875
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.893479347229004
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.14148712158203
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.4122371673584
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.064760208129883
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.147140502929688
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.357519149780273
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.191879272460938
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.806384086608887
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.572681427001953
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.90386390686035
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.762027740478516
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.214263916015625
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.098461151123047
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.217024803161621
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.43368911743164
        },
        "lm_head": {
            "bit_width": 3,
            "error": 18.552196502685547
        }
    },
    "average_bit_width": 2.786802030456853,
    "error_threshold": 12,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.33330151305426947,
        "mmlu_results": {
            "overall_score": 0.2331288343558282,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.19,\"1\":0.21,\"2\":0.2857142857}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIn the year 2154, a small, peaceful planet called Elyria was home to a thriving community of humans. The planet was known for its lush forests, vast oceans, and towering mountain ranges. The inhabitants of Elyria lived in harmony with nature, harnessing its resources to create innovative technologies that benefited the planet and its inhabitants.\n\nThe city of Elyria was a marvel of engineering, a self-sustaining metropolis that ran on 100% renewable"
    }
}