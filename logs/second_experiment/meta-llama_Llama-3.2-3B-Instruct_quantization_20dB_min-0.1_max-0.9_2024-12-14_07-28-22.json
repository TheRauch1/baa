{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 24.991764068603516
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 23.260576248168945
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.778606414794922
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 23.187482833862305
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.89682960510254
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.667381286621094
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 22.9620361328125
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 24.715740203857422
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 22.860687255859375
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.547773361206055
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.400955200195312
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.406272888183594
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.06500244140625
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 34.901451110839844
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.626605987548828
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.578502655029297
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.52200698852539
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.898054122924805
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.572267532348633
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 26.502559661865234
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.47113037109375
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.93780517578125
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.252126693725586
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.57272720336914
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.733030319213867
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.051116943359375
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.052940368652344
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.04871368408203
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 22.433712005615234
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.457338333129883
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.10264015197754
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 26.476062774658203
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.761760711669922
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.190553665161133
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.09281349182129
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.167911529541016
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.42953109741211
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.441022872924805
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.80438232421875
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 24.095325469970703
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.289724349975586
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.19424057006836
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.28178596496582
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.9671688079834
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.718446731567383
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.408056259155273
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 24.917011260986328
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.542827606201172
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.158750534057617
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.69599723815918
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.78741455078125
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.27861785888672
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.718093872070312
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 24.947200775146484
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.980985641479492
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.514354705810547
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.578672409057617
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.949676513671875
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.140371322631836
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.91790771484375
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 25.09937286376953
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.057151794433594
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.56404685974121
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.465791702270508
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.524911880493164
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.179105758666992
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.067428588867188
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 25.274486541748047
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.07573699951172
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.498668670654297
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.153724670410156
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.380722045898438
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.660335540771484
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.81812858581543
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 25.31578254699707
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.24589729309082
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.490459442138672
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.206317901611328
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.64727210998535
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.775272369384766
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.984909057617188
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 25.214384078979492
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.33795928955078
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.561098098754883
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.380842208862305
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.67056655883789
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.13820457458496
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.387615203857422
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 25.551626205444336
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.248682022094727
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.445247650146484
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.93345069885254
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 27.351154327392578
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.730939865112305
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.288360595703125
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 3,
            "error": 25.662525177001953
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.79846954345703
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.456222534179688
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 3,
            "error": 27.24921417236328
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.986120223999023
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.968502044677734
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.48297691345215
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 25.63016128540039
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.67459487915039
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.087791442871094
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.67475700378418
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.171588897705078
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.64303970336914
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.51030731201172
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 25.27670669555664
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.535219192504883
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.56615447998047
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.193889617919922
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.958354949951172
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.942073822021484
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.85559844970703
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 24.22125816345215
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.278532028198242
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.438594818115234
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.37994384765625
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.999664306640625
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.799150466918945
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.16913414001465
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.905643463134766
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.136180877685547
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.49854278564453
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.970056533813477
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.813236236572266
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.052490234375
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.568235397338867
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.6539249420166
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.121137619018555
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.3496036529541
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 3,
            "error": 27.135379791259766
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.044294357299805
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.945724487304688
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 26.272525787353516
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.682477951049805
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.25202751159668
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.07246208190918
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.193687438964844
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.80944061279297
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.064434051513672
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.98580551147461
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.04498863220215
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.02743911743164
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.042142868041992
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.5706729888916
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.185501098632812
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.332664489746094
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.961219787597656
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.638103485107422
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 26.61962127685547
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.36203956604004
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.21133804321289
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.450023651123047
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.677371978759766
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.707666397094727
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.785266876220703
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 26.57669448852539
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.297853469848633
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.719316482543945
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.651206970214844
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.540210723876953
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 4,
            "error": 26.349681854248047
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.61781883239746
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.278270721435547
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.2729549407959
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.90937614440918
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.06172752380371
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.773820877075195
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 26.495304107666016
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 24.03938102722168
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.73774528503418
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.315174102783203
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.357044219970703
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.762969970703125
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.34469223022461
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.628183364868164
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 24.541805267333984
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 22.06269073486328
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.255447387695312
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.38296890258789
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.576684951782227
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.022045135498047
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.851470947265625
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 24.718454360961914
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 23.450698852539062
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 21.30831527709961
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.982606887817383
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.20867156982422
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.83452033996582
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 22.723617553710938
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 24.52462387084961
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 26.870573043823242
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 24.529022216796875
        },
        "lm_head": {
            "bit_width": 3,
            "error": 24.14588165283203
        }
    },
    "average_bit_width": 3.050761421319797,
    "error_threshold": 20,
    "min_quantile": 0.1,
    "max_quantile": 0.9,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.47045941664336965,
        "mmlu_results": {
            "overall_score": 0.39263803680981596,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.49,\"1\":0.41,\"2\":0.3015873016}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nOnce upon a time, in a world ravaged by climate change, wars over resources, and social inequality, a small group of individuals from different walks of life came together to form a community that would change the course of human history.\n\nIn a small, coastal town, a young woman named Ava, a former scientist, had lost her family and home to the devastating floods that had ravaged the world. She had dedicated her life to finding a solution to the environmental crisis, and"
    }
}