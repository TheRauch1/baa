{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.112838745117188
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.270441055297852
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.156734466552734
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.976933479309082
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.216712951660156
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.595666885375977
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.832778930664062
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.934893608093262
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.37753677368164
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.877644538879395
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.05410385131836
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.606857299804688
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.22609806060791
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 31.49456214904785
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.253884315490723
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.67812442779541
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.055110931396484
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.97814655303955
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.30620765686035
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.745484352111816
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.949650764465332
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.779996871948242
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.760947227478027
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.582952499389648
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.48072624206543
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.021583557128906
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.952783584594727
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.885953903198242
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.45853328704834
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.671834945678711
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.454264640808105
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.307198524475098
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.894430160522461
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.05651569366455
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.722805976867676
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.47928524017334
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.028016090393066
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.657166481018066
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.968001365661621
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.100573539733887
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.16099739074707
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.55351734161377
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.928510665893555
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.240218162536621
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.023042678833008
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.582416534423828
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.739439964294434
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.418205261230469
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.631290435791016
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.267521858215332
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.101470947265625
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.48015785217285
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.358763694763184
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.618339538574219
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.681037902832031
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.472197532653809
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.72998332977295
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.273487091064453
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.76445198059082
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.643571853637695
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.647826194763184
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.649356842041016
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.394319534301758
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.208244323730469
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.848072052001953
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.53540325164795
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.439908981323242
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.748480796813965
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.762816429138184
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.342169761657715
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.06502914428711
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.44644832611084
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.05931282043457
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.596111297607422
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.697805404663086
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.728302001953125
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.267251968383789
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.584875106811523
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.987156867980957
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.65716552734375
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 10.902578353881836
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.68953800201416
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.736814498901367
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.405523300170898
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.265175819396973
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.558211326599121
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.674429893493652
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.697998046875
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.697904586791992
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.862232208251953
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.531911849975586
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.784311294555664
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.701858520507812
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.579113006591797
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 10.955220222473145
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.044724464416504
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.775592803955078
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.303847312927246
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.990976333618164
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.627141952514648
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.085790634155273
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.643876075744629
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.052899360656738
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.412565231323242
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.387031555175781
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.91370964050293
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.611842155456543
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.462355613708496
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.03236198425293
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.3363037109375
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.41075325012207
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.565738677978516
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.299202919006348
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.158690452575684
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.190980911254883
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.140753746032715
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.663130760192871
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.196427345275879
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.525991439819336
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.464393615722656
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.489214897155762
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.392643928527832
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.689035415649414
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.861383438110352
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.225046157836914
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.496582984924316
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.941507339477539
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.072725296020508
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.278894424438477
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.682827949523926
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.126996040344238
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.07148265838623
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.578392028808594
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.030132293701172
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.085206031799316
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.473090171813965
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.823033332824707
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.838134765625
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.946788787841797
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.644830703735352
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.356575012207031
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.381105422973633
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.411052703857422
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.410511016845703
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.555015563964844
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.908652305603027
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.464485168457031
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.411935806274414
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.858488082885742
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.151476860046387
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.789485931396484
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.61095142364502
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.974039077758789
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.60012435913086
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.597259521484375
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.47641372680664
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.950705528259277
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.225996017456055
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.16344928741455
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.85498332977295
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.690439224243164
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.60221004486084
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.482868194580078
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.096755027770996
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.168597221374512
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.19248390197754
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.743285179138184
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.755136489868164
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.616496086120605
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.401714324951172
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.861732482910156
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.727413177490234
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.897672653198242
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.678977966308594
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.609302520751953
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.003130912780762
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.806493759155273
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.122861862182617
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.627861976623535
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.905654907226562
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.640161514282227
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.475875854492188
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.249420166015625
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.215649604797363
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.6021089553833
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.245776176452637
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.2841739654541
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.778497695922852
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.385470390319824
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.641121864318848
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.221538543701172
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.60688304901123
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.231786727905273
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.30688762664795
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.030801773071289
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.600906372070312
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.061328887939453
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.334030151367188
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.776473045349121
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.559770584106445
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.798788070678711
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.806999206542969
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.983375549316406
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.409310340881348
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.49438190460205
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.967596054077148
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.647638320922852
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.008691787719727
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.51528549194336
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.216660499572754
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.82456111907959
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.295411109924316
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.63432502746582
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.732170104980469
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.834205627441406
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.010250091552734
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 3,
            "error": 16.870983123779297
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.722772598266602
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.766266822814941
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.556468963623047
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.666015625
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.166677474975586
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.529497146606445
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 2,
            "error": 11.89932632446289
        },
        "lm_head": {
            "bit_width": 3,
            "error": 15.817452430725098
        }
    },
    "average_bit_width": 2.582222222222222,
    "error_threshold": 10,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.29545242754636103,
        "mmlu_results": {
            "overall_score": 0.2883435582822086,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.33,\"1\":0.27,\"2\":0.2698412698}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIn the year 1943, a young boy named Jack lived in a small town in England. He lived with his grandmother, a kind-hearted woman named Clara who cooked delicious meals and took care of Jack like his mother would."
    }
}