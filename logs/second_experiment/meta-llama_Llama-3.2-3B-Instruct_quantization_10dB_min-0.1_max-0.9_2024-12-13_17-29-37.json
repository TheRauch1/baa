{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 24.991764068603516
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 23.260576248168945
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.435988426208496
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.754127502441406
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.534399032592773
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.31436538696289
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 15.615968704223633
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 24.715740203857422
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 22.860687255859375
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 2,
            "error": 14.124127388000488
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.054564476013184
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.063852310180664
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.736303329467773
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 34.901451110839844
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.626605987548828
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.578502655029297
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.22397232055664
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.455841064453125
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.219564437866211
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.516036987304688
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.101072311401367
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.93780517578125
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.252126693725586
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.234125137329102
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.30164909362793
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.671222686767578
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.70059585571289
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.682757377624512
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 22.433712005615234
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.457338333129883
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.727014541625977
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.605279922485352
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.40140151977539
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.844354629516602
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.717084884643555
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.167911529541016
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.42953109741211
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 2,
            "error": 14.053766250610352
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.813894271850586
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.746410369873047
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.920866012573242
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.825718879699707
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.28178596496582
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.9671688079834
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 2,
            "error": 14.386837005615234
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.387962341308594
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.55735206604004
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.193973541259766
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.82960033416748
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.69599723815918
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.78741455078125
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 2,
            "error": 14.932382583618164
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.729029655456543
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.607786178588867
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.617405891418457
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.520398139953613
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.578672409057617
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.949676513671875
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 2,
            "error": 14.763246536254883
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.24712562561035
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.732030868530273
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.684307098388672
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.59386157989502
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.465791702270508
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.524911880493164
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 2,
            "error": 14.741779327392578
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.113619804382324
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.93893051147461
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.74061393737793
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.525737762451172
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.153724670410156
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.380722045898438
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 2,
            "error": 15.272931098937988
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.21395492553711
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.962574005126953
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.916436195373535
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.55047607421875
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.206317901611328
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.64727210998535
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 2,
            "error": 14.429408073425293
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.013059616088867
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.861644744873047
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.993663787841797
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.597637176513672
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.99111557006836
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.384920120239258
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 2,
            "error": 14.773150444030762
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.708765029907227
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.21344757080078
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.905678749084473
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.444199562072754
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.548782348632812
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.902576446533203
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 2,
            "error": 14.436027526855469
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.377208709716797
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.319366455078125
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.431671142578125
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.470977783203125
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.932262420654297
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.685638427734375
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.596561431884766
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.51338005065918
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.274456024169922
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.314271926879883
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.70002269744873
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.26593589782715
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.841236114501953
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.350205421447754
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.567667961120605
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.914838790893555
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.168062210083008
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.606993675231934
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.866668701171875
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.49127197265625
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.598394393920898
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.859655380249023
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.852157592773438
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.908984184265137
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.46000862121582
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.992511749267578
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.601696014404297
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.549819946289062
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.170319557189941
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.579029083251953
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.779706954956055
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.544713020324707
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.553340911865234
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.43689727783203
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.668984413146973
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.579694747924805
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.29001235961914
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.790454864501953
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.368093490600586
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.752710342407227
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.909269332885742
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.579952239990234
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.365785598754883
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.32522964477539
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.907726287841797
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.695073127746582
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.940921783447266
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.406442642211914
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.756715774536133
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.104793548583984
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.650426864624023
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.666426658630371
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.696653366088867
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.150203704833984
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.66967010498047
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.979232788085938
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.923744201660156
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.27861499786377
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.66065788269043
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.360418319702148
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.21133804321289
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.197294235229492
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.348259925842285
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.242061614990234
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.471678733825684
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.598493576049805
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.342918395996094
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.37816619873047
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.191457748413086
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.494436264038086
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.42398452758789
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.21849250793457
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.9166259765625
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.280964851379395
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.57477569580078
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.56241798400879
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.291667938232422
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.496195793151855
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.706344604492188
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.39266586303711
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.879385948181152
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.725664138793945
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.35149574279785
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.959698677062988
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.082575798034668
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.127355575561523
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.72559928894043
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.89561653137207
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.04602813720703
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.31503677368164
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.637015342712402
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.426872253417969
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.392471313476562
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 2,
            "error": 16.053287506103516
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.982812881469727
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 20.982606887817383
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.20867156982422
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.477117538452148
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.401468276977539
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.187402725219727
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 2,
            "error": 19.52428436279297
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 2,
            "error": 17.143341064453125
        },
        "lm_head": {
            "bit_width": 2,
            "error": 16.77077865600586
        }
    },
    "average_bit_width": 2.015228426395939,
    "error_threshold": 10,
    "min_quantile": 0.1,
    "max_quantile": 0.9,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.4233529028049576,
        "mmlu_results": {
            "overall_score": 0.3312883435582822,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.35,\"1\":0.36,\"2\":0.2936507937}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 13 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nOnce upon a time, in a world ravaged by climate change and pollution, humanity was on the brink of collapse. Rising sea levels had swallowed coastal cities, drought-stricken lands had become deserts, and the once blue skies were now a permanent gray haze.\n\nBut amidst the chaos, a small community in a small village in the mountains discovered a glimmer of hope. They had stumbled upon a hidden underground bunker, built by a secret organization of scientists who had predicted the impending doom"
    }
}