{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "original_model_accuracy": 0.4633191733091499,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.4974946975708
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.216886520385742
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.241142272949219
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 4,
            "error": 11.219206809997559
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.350279808044434
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.08648681640625
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 4,
            "error": 11.953707695007324
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 17.523469924926758
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.698017120361328
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 11.293584823608398
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 4,
            "error": 11.393390655517578
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 10.036078453063965
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 4,
            "error": 14.751895904541016
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 8,
            "error": 21.62992286682129
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 3,
            "error": 12.64042854309082
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.074115753173828
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.635858535766602
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 4,
            "error": 12.046542167663574
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.5515079498291
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.14657211303711
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 4,
            "error": 12.402008056640625
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 3,
            "error": 17.352243423461914
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.90132713317871
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 11.136024475097656
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 4,
            "error": 14.46225357055664
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 10.008807182312012
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.54367446899414
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.715587615966797
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.033527374267578
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.09618377685547
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 11.022768020629883
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 13.606451988220215
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 11.606525421142578
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 4,
            "error": 14.83851432800293
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.16356086730957
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.870597839355469
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.37671184539795
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 11.314550399780273
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 13.400670051574707
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 12.200112342834473
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.010740280151367
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 4,
            "error": 14.654472351074219
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.261331558227539
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.384199142456055
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.457069396972656
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 13.541547775268555
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 12.336262702941895
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.474366188049316
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.593873977661133
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 16.983135223388672
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.941247940063477
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.843708992004395
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 13.586573600769043
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 12.545736312866211
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.574246406555176
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.253983497619629
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.869003295898438
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.580278396606445
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.047727584838867
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 12.45402717590332
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 12.426508903503418
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.769630432128906
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.106258392333984
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.710670471191406
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.984908103942871
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 11.571456909179688
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 12.48622989654541
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 11.67020320892334
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.022380828857422
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 14.990548133850098
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.886990547180176
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.93045711517334
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.875738143920898
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 11.745248794555664
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 11.242973327636719
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.916394233703613
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.080023765563965
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 3,
            "error": 16.809219360351562
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.302165985107422
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.387328147888184
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 12.591896057128906
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 10.657081604003906
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.01900577545166
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 4,
            "error": 14.214157104492188
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.420440673828125
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.865189552307129
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.074739456176758
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 11.3486967086792
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.927773475646973
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.0172700881958
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.337656021118164
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.490313529968262
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.792732238769531
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 11.187118530273438
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 12.925117492675781
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.576611518859863
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 4,
            "error": 14.971006393432617
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 14.823150634765625
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 3,
            "error": 12.910370826721191
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.22981071472168
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.767993927001953
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 12.939635276794434
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.816473007202148
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.318408966064453
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.50680923461914
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.768109321594238
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.618480682373047
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 11.113521575927734
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 12.967798233032227
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.512025833129883
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.874652862548828
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 10.169740676879883
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.676885604858398
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.502219200134277
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.672626495361328
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 4,
            "error": 13.048002243041992
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.958415985107422
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.090015411376953
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 14.28083610534668
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.546701431274414
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.844244003295898
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 11.069518089294434
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 4,
            "error": 13.554716110229492
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.985140800476074
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.132699966430664
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 5,
            "error": 16.83023452758789
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 12.59926986694336
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.405288696289062
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.562692642211914
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 13.908472061157227
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.025068283081055
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.044462203979492
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.835458755493164
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.99079418182373
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.19884204864502
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.285432815551758
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 11.300887107849121
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.593833923339844
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.57829475402832
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.603293418884277
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.915873527526855
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.4136962890625
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.647231101989746
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 14.493997573852539
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.005245208740234
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.292152404785156
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 4,
            "error": 13.517159461975098
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.633554458618164
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 12.988748550415039
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.26703929901123
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.25843620300293
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.44886589050293
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.05463218688965
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.943842887878418
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 14.623918533325195
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 12.974466323852539
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.574491500854492
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 4,
            "error": 14.00820541381836
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.642086029052734
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.132131576538086
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 13.25
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.352961540222168
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 12.9600191116333
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.038467407226562
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 4,
            "error": 14.337807655334473
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.924474716186523
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.51303482055664
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 14.653289794921875
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.596400260925293
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 12.868012428283691
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.19408416748047
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.722769737243652
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 10.04666519165039
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 10.078702926635742
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 10.255834579467773
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.515711784362793
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.507851600646973
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 10.021615982055664
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 4,
            "error": 14.593949317932129
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 10.368271827697754
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 10.659161567687988
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.652107238769531
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 13.661382675170898
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 12.891230583190918
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 15.6201753616333
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 4,
            "error": 14.64735221862793
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 10.785316467285156
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 12.236381530761719
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.185328483581543
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.136411666870117
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.43543815612793
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 15.274802207946777
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 5,
            "error": 16.34228515625
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.570962905883789
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 10.506696701049805
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 4,
            "error": 12.160492897033691
        },
        "lm_head": {
            "bit_width": 3,
            "error": 12.40015983581543
        }
    },
    "average_bit_width": 3.527918781725888,
    "error_threshold": 10,
    "min_quantile": 0,
    "max_quantile": 1,
    "quantized_model_accuracy": 0.28643024199322226
}