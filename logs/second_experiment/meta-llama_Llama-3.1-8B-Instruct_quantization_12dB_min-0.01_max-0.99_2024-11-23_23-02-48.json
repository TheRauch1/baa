{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "original_model_accuracy": 0.5299508376688463,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.097234725952148
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.19271183013916
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.320127487182617
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.50315284729004
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.985475540161133
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.556482315063477
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.11443328857422
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.939565658569336
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.326383590698242
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.952857971191406
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.352324485778809
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.829011917114258
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.36848258972168
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 31.429115295410156
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.22300910949707
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.333206176757812
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.13400936126709
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.904874801635742
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.412918090820312
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.858616828918457
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.992585182189941
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.831799507141113
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.799869537353516
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.599414825439453
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.649169921875
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.197772979736328
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.019754409790039
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.909635543823242
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.476377487182617
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.65330696105957
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.353055953979492
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.605426788330078
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.26140785217285
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.0695219039917
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.73082447052002
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.483736038208008
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.104676246643066
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.602218627929688
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.870047569274902
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.40739631652832
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.219467163085938
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.6055908203125
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.855599403381348
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.211024284362793
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.063547134399414
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.310586929321289
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.043170928955078
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.484901428222656
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.65877628326416
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.318979263305664
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.158968925476074
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.435253143310547
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.254384994506836
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.918149948120117
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.73048210144043
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.475302696228027
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.82504653930664
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.34674072265625
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.595983505249023
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.22020149230957
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.036209106445312
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.710982322692871
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.410160064697266
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.219758033752441
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.729000091552734
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.51182746887207
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.96198081970215
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.105640411376953
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.821223258972168
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.362293243408203
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.110405921936035
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.197134017944336
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.885272979736328
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.221525192260742
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.049198150634766
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.774961471557617
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.272761344909668
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.684989929199219
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.006509780883789
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.513324737548828
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.222993850708008
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.04498291015625
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.73885726928711
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.352893829345703
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.306255340576172
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.494913101196289
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.57425308227539
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.38320541381836
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.139101028442383
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.86087417602539
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.55557632446289
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.097177505493164
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.989078521728516
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.497575759887695
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.6290225982666
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.158649444580078
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.872308731079102
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.29439926147461
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.12185287475586
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.103775024414062
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.041390419006348
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.198469161987305
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.197937965393066
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.502193450927734
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.357528686523438
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.132266998291016
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.11350440979004
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.374536514282227
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.41718292236328
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.485725402832031
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.526369094848633
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.492424011230469
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.289142608642578
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.58232879638672
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.211478233337402
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.434395790100098
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.1273193359375
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.321036338806152
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.504945755004883
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.478233337402344
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.023027420043945
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.343631744384766
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.658037185668945
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.21529197692871
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.331221580505371
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.442816734313965
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.039985656738281
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.654067993164062
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.441650390625
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.823297500610352
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.456573486328125
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.175369262695312
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.494805335998535
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.100602149963379
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.65839195251465
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.52048397064209
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.942028999328613
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.10873031616211
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.053505897521973
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.609679222106934
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.485485076904297
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.021175384521484
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.297466278076172
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.511029243469238
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.855022430419922
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.012800216674805
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.441587448120117
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.401408195495605
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.490158081054688
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.166170120239258
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.889602661132812
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.880937576293945
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.067625045776367
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.563304901123047
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.710338592529297
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.815542221069336
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.098417282104492
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.237512588500977
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.454225540161133
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.946451187133789
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.585824966430664
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.931346893310547
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.18756675720215
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.21802043914795
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.253217697143555
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.09556770324707
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.812773704528809
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.650411605834961
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.833982467651367
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.870882034301758
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.03957462310791
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.625747680664062
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.78739356994629
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.756305694580078
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.578858375549316
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.116098403930664
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.374780654907227
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.193190574645996
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.594307899475098
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.828462600708008
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.704941749572754
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.455050468444824
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.418075561523438
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.860618591308594
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.70627498626709
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.871268272399902
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.17833709716797
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.80077838897705
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.408899307250977
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.834545135498047
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.98610496520996
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.648258209228516
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.370893478393555
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.54572105407715
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.013833999633789
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.589041709899902
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.11960220336914
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.920305252075195
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.871395111083984
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.158737182617188
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.100183486938477
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.713741302490234
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.893218040466309
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.337568283081055
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.557493209838867
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.010138511657715
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.665903091430664
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.353139877319336
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.422616958618164
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.050116539001465
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.021743774414062
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.53070640563965
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.838651657104492
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.727790832519531
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.161191940307617
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.272964477539062
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 3,
            "error": 16.727781295776367
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.723725318908691
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.711516380310059
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.390726089477539
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.651399612426758
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.86574649810791
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.348517417907715
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.20174789428711
        },
        "lm_head": {
            "bit_width": 3,
            "error": 15.514396667480469
        }
    },
    "average_bit_width": 2.8577777777777778,
    "error_threshold": 12,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_accuracy": 0.41883442317789127
}