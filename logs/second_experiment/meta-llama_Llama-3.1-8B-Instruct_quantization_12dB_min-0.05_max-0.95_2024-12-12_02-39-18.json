{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "original_model_benchmarks": {
        "wikitext_accuracy": 0.5299508376688463,
        "mmlu_results": {
            "overall_score": 0.6165644171779141,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.67,\"1\":0.73,\"2\":0.4841269841}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIn the year 2154, the world had finally reached a point of perfect harmony. After centuries of wars, conflicts, and environmental disasters, humanity had come together to form a united global government, dedicated to the well-being of all people and the planet.\n\nThe city of New Eden, a marvel of modern technology, was the capital of this new world order. Towering skyscrapers made of sustainable materials stretched towards the sky, their exteriors covered in lush greenery and"
    },
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.698883056640625
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.999937057495117
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.402841567993164
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.578690528869629
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.945847511291504
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.805591583251953
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 14.19526195526123
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.0732479095459
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.553110122680664
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.669254302978516
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.820244789123535
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.674880981445312
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.50811195373535
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 37.33299255371094
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.737407684326172
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.44002342224121
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.715322494506836
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.109277725219727
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.239002227783203
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.95717430114746
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.365623474121094
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.234153747558594
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.16605567932129
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.967958450317383
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.794754028320312
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.096961975097656
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.142541885375977
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.06000518798828
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.410404205322266
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.338586807250977
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.976457595825195
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.90142822265625
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.276458740234375
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.325170516967773
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.82600212097168
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.229848861694336
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.286880493164062
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.11199951171875
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.994159698486328
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.396764755249023
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.467973709106445
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.8007869720459
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.26568603515625
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.8056640625
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.30699348449707
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.406246185302734
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.106087684631348
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.75735092163086
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.78472328186035
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.790157318115234
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.599239349365234
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.506534576416016
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.476978302001953
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.024694442749023
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.045703887939453
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.577829360961914
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.283504486083984
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.66196060180664
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.38970375061035
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.81089973449707
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.152408599853516
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.01289176940918
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.534196853637695
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.871610641479492
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.01842498779297
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.126581192016602
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.561108589172363
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.277700424194336
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.135364532470703
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.49788475036621
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.767881393432617
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.844715118408203
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.326889991760254
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.85479736328125
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.16748332977295
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.037830352783203
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.429988861083984
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.034011840820312
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.156356811523438
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.666092872619629
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.894794464111328
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.26740837097168
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.022428512573242
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.518310546875
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.462526321411133
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.707855224609375
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.08806037902832
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.918376922607422
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.470799446105957
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.270288467407227
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.732315063476562
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.361711502075195
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.665422439575195
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.18145751953125
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.229894638061523
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.8123779296875
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.255027770996094
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.433292388916016
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.552104949951172
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.121339797973633
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.06996726989746
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.819599151611328
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.98260498046875
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.89531707763672
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.453611373901367
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.656604766845703
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.289451599121094
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.020830154418945
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.970048904418945
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.101707458496094
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.849315643310547
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.607295989990234
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.61766815185547
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.451072692871094
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.26435661315918
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.626598358154297
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.379440307617188
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.568660736083984
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.60148811340332
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.72542953491211
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.645082473754883
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.932891845703125
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.773075103759766
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.429424285888672
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.52660369873047
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.55039405822754
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.003644943237305
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.626030921936035
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.100364685058594
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.94634246826172
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.54576301574707
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.308523178100586
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.575721740722656
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.198389053344727
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.708380699157715
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.02928352355957
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.04107093811035
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.162939071655273
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.16180992126465
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.69974136352539
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.56878662109375
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.162534713745117
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.973716735839844
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.78186798095703
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.854057312011719
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.108867645263672
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.555444717407227
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.610694885253906
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.524856567382812
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.23297691345215
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.086856842041016
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.874417304992676
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.136598587036133
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.687929153442383
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.765789985656738
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.139121055603027
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.669546127319336
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.35957908630371
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.365754127502441
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.9959716796875
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.680755615234375
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.002967834472656
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.41504955291748
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.682926177978516
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.28874969482422
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.01079273223877
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.87186050415039
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.764280319213867
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.037338256835938
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.586362838745117
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.71255874633789
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.69866943359375
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.713361740112305
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.817520141601562
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.634784698486328
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.663333892822266
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.220739364624023
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.99564552307129
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.728656768798828
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.775314331054688
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.77840805053711
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.533451080322266
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.53920841217041
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.16899299621582
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.545272827148438
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.95319366455078
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.220039367675781
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.864286422729492
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.48429298400879
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.923250198364258
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.434812545776367
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.818681716918945
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.456422805786133
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.667390823364258
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.090492248535156
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.67971420288086
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.148950576782227
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.759529113769531
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.668624877929688
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.185728073120117
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.298380851745605
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.836036682128906
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.93841552734375
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.958269119262695
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.799699783325195
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.96858787536621
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.72511863708496
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.655487060546875
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.194291114807129
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.122547149658203
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.139699935913086
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.836385726928711
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.883047103881836
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.775192260742188
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.598841667175293
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.079221725463867
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 2,
            "error": 12.608695030212402
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.799423217773438
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.69071388244629
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.3485107421875
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.031978607177734
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.641550064086914
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 2,
            "error": 17.593242645263672
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 2,
            "error": 15.485373497009277
        },
        "lm_head": {
            "bit_width": 3,
            "error": 18.821805953979492
        }
    },
    "average_bit_width": 2.502222222222222,
    "error_threshold": 12,
    "min_quantile": 0.05,
    "max_quantile": 0.95,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.4676149109827693,
        "mmlu_results": {
            "overall_score": 0.4447852760736196,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.53,\"1\":0.49,\"2\":0.3412698413}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\n**The Story of Hope**\n\nIn a world ravaged by war, famine, and despair, humanity teetered on the brink of collapse. The once blue skies were now a dull gray, and the only sound was the endless drone of sirens and the rustling of the last remnants of the world's flora.\n\nA young girl named Aria, barely ten years old, wandered the desolate streets, her eyes scanning the horizon for any sign of hope. She had lost"
    }
}