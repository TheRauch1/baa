{
    "model_name": "HuggingFaceTB/SmolLM-135M-Instruct",
    "original_model_accuracy": 0.39463618573207615,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.373942375183105
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.359529495239258
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 2,
            "error": 15.372493743896484
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 20.5768985748291
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.892814636230469
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.855226516723633
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 16.830753326416016
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.391700744628906
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.223271369934082
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.359293937683105
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 2,
            "error": 16.927473068237305
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.289915084838867
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.014972686767578
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.811911582946777
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.376880645751953
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.398527145385742
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.136415481567383
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.901796340942383
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.00804901123047
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.709871292114258
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.549446105957031
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.105320930480957
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.036123275756836
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.88118553161621
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.81707000732422
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.583477020263672
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.527822494506836
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.80746078491211
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.532639503479004
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.833192825317383
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.3126220703125
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.25850486755371
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.1690616607666
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.491052627563477
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.75537109375
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.562518119812012
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.335124015808105
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.343263626098633
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.462844848632812
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.040754318237305
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.639867782592773
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.97333526611328
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.35706901550293
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.258338928222656
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.296981811523438
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.758996963500977
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.950973510742188
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.671607971191406
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.99334144592285
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.023476600646973
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.67090606689453
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.785049438476562
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.94049072265625
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.012296676635742
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.928443908691406
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.972978591918945
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.326613426208496
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.554594039916992
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.425329208374023
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.829471588134766
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.097887992858887
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.82433319091797
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.394954681396484
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.000883102416992
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.80982208251953
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.111462593078613
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.485918045043945
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.158538818359375
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.835479736328125
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.132875442504883
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.087687492370605
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.84365463256836
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.398679733276367
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.990402221679688
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.759871482849121
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.86962890625
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.887653350830078
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.254846572875977
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.79024887084961
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.218687057495117
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.851211547851562
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.342525482177734
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.01696014404297
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 36.45428466796875
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.762421607971191
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.560359954833984
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.641239166259766
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.737812042236328
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.112621307373047
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.164321899414062
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 2,
            "error": 14.156508445739746
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.030875205993652
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.468504905700684
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.151326179504395
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.33487319946289
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.220282554626465
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.25633430480957
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.049968719482422
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.535701751708984
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.559842109680176
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.815855026245117
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.815153121948242
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.899904251098633
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.293867111206055
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.77540397644043
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.593153953552246
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.295303344726562
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.3940372467041
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.337886810302734
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.88656234741211
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.126314163208008
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.761966705322266
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.826128959655762
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.453022003173828
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.652362823486328
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.66813850402832
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.03631591796875
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.111461639404297
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.661020278930664
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.42739200592041
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.949028015136719
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.422863006591797
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.14602279663086
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.032546997070312
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.181055068969727
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.72292709350586
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.165334701538086
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.133330345153809
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.4529972076416
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.756507873535156
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.23517417907715
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.173297882080078
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.699129104614258
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.639251708984375
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.804771423339844
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.835420608520508
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.16633415222168
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.075089454650879
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.194700241088867
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.57225227355957
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.474295616149902
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.54683780670166
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.06923484802246
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.111494064331055
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.102221488952637
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.349668502807617
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.837553024291992
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.488472938537598
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.276410102844238
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.18684196472168
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.492748260498047
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.111786842346191
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.61714744567871
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.129638671875
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.967886924743652
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.977761268615723
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.890886306762695
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.657175064086914
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.02889060974121
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.186786651611328
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.05022430419922
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.775996208190918
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.582355499267578
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.073137283325195
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.077241897583008
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.840526580810547
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.049848556518555
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.89630126953125
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.211469650268555
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.785261154174805
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.284130096435547
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.460687637329102
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.568103790283203
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.193771362304688
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.769563674926758
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.418611526489258
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.286762237548828
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.737756729125977
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.984415054321289
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.580949783325195
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.048954010009766
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.752429962158203
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.939399719238281
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.763875961303711
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.702367782592773
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 2,
            "error": 18.210281372070312
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.55374526977539
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.159502029418945
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.41903305053711
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.892007827758789
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.786188125610352
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.44927406311035
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.073371887207031
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.48180389404297
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.13868522644043
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.76540756225586
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.351763725280762
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.664604187011719
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.251588821411133
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.425811767578125
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.606687545776367
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.01298713684082
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 2,
            "error": 24.739187240600586
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.09326171875
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.947977066040039
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.40835952758789
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.750711441040039
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.950424194335938
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.731722831726074
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 2,
            "error": 15.363107681274414
        },
        "lm_head": {
            "bit_width": 2,
            "error": 14.328621864318848
        }
    },
    "average_bit_width": 2.5829383886255926,
    "error_threshold": 12,
    "min_quantile": 0.05,
    "max_quantile": 0.95,
    "quantized_model_accuracy": 0.300613769791852
}