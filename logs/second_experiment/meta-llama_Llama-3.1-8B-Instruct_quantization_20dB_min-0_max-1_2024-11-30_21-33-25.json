{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "original_model_accuracy": 0.5299508376688463,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.87803840637207
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.38760757446289
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.250263214111328
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 6,
            "error": 23.001144409179688
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 5,
            "error": 20.881427764892578
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.58234405517578
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 6,
            "error": 20.171009063720703
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 4,
            "error": 23.843212127685547
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 4,
            "error": 26.174713134765625
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.95037078857422
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 6,
            "error": 22.896053314208984
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 5,
            "error": 20.675657272338867
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.72291374206543
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 10,
            "error": 33.843849182128906
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.11713218688965
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.443418502807617
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.702762603759766
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.516033172607422
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.593172073364258
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.40334129333496
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.574012756347656
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 4,
            "error": 23.35109519958496
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.941410064697266
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 5,
            "error": 24.151344299316406
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 6,
            "error": 26.00152015686035
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.837446212768555
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.44183349609375
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.821958541870117
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.30109405517578
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.118000030517578
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 5,
            "error": 24.096763610839844
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.904573440551758
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 5,
            "error": 23.130084991455078
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.79080581665039
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.76601219177246
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.840089797973633
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.314332962036133
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.78902244567871
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.155426025390625
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 5,
            "error": 23.76797866821289
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.111042022705078
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.775033950805664
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.103010177612305
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.157495498657227
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 5,
            "error": 24.87879180908203
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.90130615234375
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 5,
            "error": 24.160072326660156
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.43956756591797
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.04662322998047
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 4,
            "error": 22.360496520996094
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.50354766845703
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 5,
            "error": 25.150869369506836
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.849685668945312
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 5,
            "error": 24.040637969970703
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.161184310913086
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.911645889282227
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 5,
            "error": 24.625408172607422
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.478612899780273
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.384078979492188
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 6,
            "error": 23.770000457763672
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 5,
            "error": 24.14364242553711
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.151317596435547
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.88886070251465
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.14923667907715
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.813919067382812
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.452178955078125
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 6,
            "error": 23.78940200805664
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 5,
            "error": 23.88729476928711
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.310834884643555
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.89409828186035
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 5,
            "error": 24.904672622680664
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.65857696533203
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.804828643798828
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 6,
            "error": 23.696361541748047
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 5,
            "error": 24.088916778564453
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.695241928100586
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.636262893676758
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.64105224609375
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.248931884765625
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 5,
            "error": 24.643457412719727
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 6,
            "error": 22.94330596923828
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 5,
            "error": 23.304473876953125
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.43612289428711
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.8651123046875
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.869983673095703
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.44275665283203
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.980274200439453
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 6,
            "error": 22.5113468170166
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.715377807617188
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.754671096801758
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 6,
            "error": 25.83041763305664
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.81618881225586
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 5,
            "error": 26.21854019165039
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.360355377197266
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 6,
            "error": 22.589744567871094
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.971891403198242
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.956546783447266
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.58548355102539
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.692575454711914
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 5,
            "error": 25.962791442871094
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.16385269165039
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.421527862548828
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.624948501586914
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.80154800415039
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.21661376953125
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 5,
            "error": 24.996658325195312
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.91909408569336
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.07651710510254
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 6,
            "error": 23.783924102783203
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.288341522216797
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.1903018951416
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.5860652923584
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.147937774658203
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.257278442382812
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.704647064208984
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.136863708496094
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.776409149169922
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.564891815185547
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 6,
            "error": 24.51694107055664
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.085622787475586
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 5,
            "error": 25.961435317993164
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.364971160888672
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.50949478149414
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.923919677734375
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.602657318115234
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 6,
            "error": 23.783512115478516
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.009340286254883
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.972097396850586
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.296737670898438
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.870153427124023
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.659297943115234
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.22203254699707
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 6,
            "error": 23.033550262451172
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.853130340576172
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.662147521972656
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.529502868652344
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 6,
            "error": 24.869396209716797
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.290599822998047
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.944820404052734
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 6,
            "error": 22.483596801757812
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.546695709228516
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.02155113220215
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.049827575683594
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.303028106689453
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.39093589782715
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.060049057006836
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.01413345336914
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.04964828491211
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.968263626098633
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.863100051879883
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 6,
            "error": 22.402740478515625
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.553024291992188
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.753173828125
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 6,
            "error": 25.97458267211914
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.70673370361328
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.01297378540039
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.333786010742188
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.147809982299805
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.487564086914062
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.275421142578125
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.273286819458008
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.771602630615234
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.397171020507812
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.423904418945312
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.0943603515625
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.155895233154297
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.061002731323242
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.014047622680664
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.49789810180664
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 5,
            "error": 25.90479850769043
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.11256217956543
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 5,
            "error": 21.101177215576172
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.04863739013672
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.923831939697266
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.637910842895508
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.312036514282227
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 5,
            "error": 26.331268310546875
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.3109073638916
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 6,
            "error": 25.79728889465332
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.866323471069336
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.793548583984375
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 6,
            "error": 24.648954391479492
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.382802963256836
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 5,
            "error": 26.32319450378418
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.35549545288086
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.084972381591797
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 5,
            "error": 21.99140739440918
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.027095794677734
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 6,
            "error": 26.32451057434082
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.556060791015625
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 5,
            "error": 26.26251220703125
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.431114196777344
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.748777389526367
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.53078842163086
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 5,
            "error": 22.30023193359375
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.77491569519043
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.60596466064453
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.182300567626953
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.708675384521484
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 6,
            "error": 26.02165985107422
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.693496704101562
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.948150634765625
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.31903076171875
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.127016067504883
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.777271270751953
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 5,
            "error": 22.52529525756836
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 5,
            "error": 21.085451126098633
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 5,
            "error": 22.74362564086914
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 5,
            "error": 23.246213912963867
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 6,
            "error": 25.280323028564453
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.18585205078125
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.0284423828125
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 5,
            "error": 21.848419189453125
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 5,
            "error": 21.5662841796875
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 5,
            "error": 24.218900680541992
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 5,
            "error": 24.64155387878418
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.60047721862793
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 4,
            "error": 22.433208465576172
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 4,
            "error": 23.296871185302734
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 5,
            "error": 23.57057762145996
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 6,
            "error": 23.07854652404785
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 5,
            "error": 26.27906036376953
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 5,
            "error": 26.05544662475586
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 6,
            "error": 22.82261848449707
        },
        "lm_head": {
            "bit_width": 5,
            "error": 20.55316162109375
        }
    },
    "average_bit_width": 5.017777777777778,
    "error_threshold": 20,
    "min_quantile": 0,
    "max_quantile": 1,
    "quantized_model_accuracy": 0.5163953987876474
}