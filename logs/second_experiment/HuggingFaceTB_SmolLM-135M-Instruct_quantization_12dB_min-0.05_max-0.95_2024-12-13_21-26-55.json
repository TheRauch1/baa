{
    "model_name": "HuggingFaceTB/SmolLM-135M-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.425419807434082
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.351463317871094
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 2,
            "error": 15.313277244567871
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 20.823394775390625
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.6108980178833
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.82468605041504
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 16.820505142211914
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.38075065612793
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.22140884399414
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.156907081604004
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 2,
            "error": 16.803306579589844
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.202726364135742
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.974872589111328
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 14.037406921386719
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.360249519348145
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.412075996398926
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.879432678222656
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.855152130126953
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.102401733398438
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.740270614624023
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.816739082336426
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.119087219238281
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.051252365112305
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.877525329589844
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.88552474975586
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.679027557373047
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.51044464111328
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.28607749938965
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.511062622070312
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.919931411743164
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.358335494995117
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.28050994873047
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.245655059814453
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.472412109375
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.714536666870117
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.500666618347168
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.380437850952148
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.352224349975586
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.53097915649414
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.074621200561523
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.657014846801758
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.941226959228516
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.285839080810547
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.291375160217285
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.318078994750977
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.460357666015625
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.95328712463379
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.693349838256836
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.99123764038086
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.005817413330078
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.692737579345703
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.79628562927246
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.943571090698242
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.119962692260742
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.978464126586914
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.039472579956055
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.341336250305176
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.594437599182129
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.302553176879883
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.842247009277344
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.04818344116211
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.842727661132812
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.396804809570312
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.099485397338867
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.688949584960938
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.34557342529297
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.54755401611328
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.19605255126953
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.827531814575195
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.06727409362793
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.104570388793945
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.63375473022461
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.28765869140625
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.15802764892578
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.857833862304688
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.88164520263672
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.895158767700195
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.296043395996094
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.770442962646484
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.12120819091797
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.673847198486328
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.288899421691895
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.996191024780273
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 36.107757568359375
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.801674842834473
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.735967636108398
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.553512573242188
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.652013778686523
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.077167510986328
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.187076568603516
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 2,
            "error": 14.120369911193848
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.029875755310059
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.479401588439941
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.095531463623047
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.28260040283203
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.147680282592773
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.223875045776367
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.06586456298828
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.66142749786377
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.674849510192871
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.815755844116211
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.0133056640625
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.83203125
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.265409469604492
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.785425186157227
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.633593559265137
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.301800727844238
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.42313003540039
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.42463493347168
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.88486671447754
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.103763580322266
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.761924743652344
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.891948699951172
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.46515941619873
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.654394149780273
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.664106369018555
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.010496139526367
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.107940673828125
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.675506591796875
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.503451347351074
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.98183536529541
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.460702896118164
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.329919815063477
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.987564086914062
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.22303009033203
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.809112548828125
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.144968032836914
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.21599006652832
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.407060623168945
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.273944854736328
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.22010040283203
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.0692195892334
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.643898010253906
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.652616500854492
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.77489948272705
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.808137893676758
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.173233032226562
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.022906303405762
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.119503021240234
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.590181350708008
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.477493286132812
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.448579788208008
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.96277618408203
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.01421546936035
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.00529956817627
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.34499168395996
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.854700088500977
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.564725875854492
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.306763648986816
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.169410705566406
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.599063873291016
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.094740867614746
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.552978515625
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.05035400390625
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.999357223510742
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.05213737487793
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.69038200378418
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.198351860046387
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.96579360961914
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.129138946533203
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.020015716552734
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.772343635559082
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.58148193359375
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.88808250427246
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.514106750488281
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.769710540771484
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.911693572998047
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.764171600341797
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.198670387268066
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.669902801513672
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.14250373840332
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.966558456420898
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.51436996459961
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.060129165649414
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.74946403503418
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.375639915466309
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.240464210510254
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.49090576171875
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 2,
            "error": 14.542498588562012
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.48722267150879
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 17.96498680114746
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.6761417388916
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.832212448120117
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.81300163269043
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.449172973632812
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 2,
            "error": 18.159961700439453
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.48703384399414
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.096254348754883
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.230680465698242
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.788713455200195
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.909690856933594
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.29420280456543
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.821330070495605
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.407304763793945
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.088781356811523
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 17.761093139648438
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.346393585205078
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.601821899414062
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.28476333618164
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.168055534362793
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.677318572998047
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.035888671875
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 2,
            "error": 24.51063346862793
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.025165557861328
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.853828430175781
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.520273208618164
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.645115852355957
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.934412002563477
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.735734939575195
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 2,
            "error": 15.519063949584961
        },
        "lm_head": {
            "bit_width": 2,
            "error": 14.259683609008789
        }
    },
    "average_bit_width": 2.5876777251184833,
    "error_threshold": 12,
    "min_quantile": 0.05,
    "max_quantile": 0.95,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.3356381822135247,
        "mmlu_results": {
            "overall_score": 0.294478527607362,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.3,\"1\":0.3,\"2\":0.2857142857}}"
        },
        "sanity_check_string": "user\nTell a short story of humanity with happy ending\nnassistantassadors, you can use.\n\n\"This story, I've come across, is about a group of students who were living with, a mysterious, people who had been in power, have. I'm afraid, I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, you, I, I, I, I, I, I"
    }
}