{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "original_model_accuracy": 0.4633191733091499,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.668914794921875
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.100831985473633
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.947021484375
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.381153106689453
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.355247497558594
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.189831733703613
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.498245239257812
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.0415096282959
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.838247299194336
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.831066131591797
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.99980640411377
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.860940933227539
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.592948913574219
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 28.024322509765625
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.729896545410156
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.734745025634766
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.014771461486816
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.772469520568848
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.206496238708496
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.486124038696289
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.894500732421875
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.383769989013672
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.63238525390625
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.10490608215332
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.169571876525879
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.892654418945312
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.590299606323242
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.452622413635254
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.859718322753906
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.911052703857422
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.419290542602539
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.42646598815918
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.263997077941895
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.67032241821289
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.501412391662598
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.659852981567383
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.836383819580078
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.782940864562988
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.87818717956543
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.614945411682129
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.818778991699219
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.554815292358398
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.696578979492188
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.512866973876953
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.205253601074219
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.54570770263672
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.328673362731934
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.069598197937012
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.552274703979492
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.177305221557617
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.324682235717773
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.730472564697266
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.872955322265625
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.400144577026367
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.473393440246582
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.293081283569336
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.001293182373047
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.091175079345703
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.426342010498047
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.09697437286377
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.516419410705566
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.514598846435547
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.328042984008789
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.712020874023438
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.620174407958984
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.419877052307129
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.089576721191406
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.638947486877441
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.53719711303711
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.21782398223877
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.586387634277344
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.425899505615234
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 2,
            "error": 13.141860961914062
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.730029106140137
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.773663520812988
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.722867965698242
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.245343208312988
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.816455841064453
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.18148422241211
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.21692180633545
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.03010368347168
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.643839836120605
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.76602554321289
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.425039291381836
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.412084579467773
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.304672241210938
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.553333282470703
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.458133697509766
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.883052825927734
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.685750961303711
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.196532249450684
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.077550888061523
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.797080993652344
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.071359634399414
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.248357772827148
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.124202728271484
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.193220138549805
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.251440048217773
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.173837661743164
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.742101669311523
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.004752159118652
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.617178916931152
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.09781837463379
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.079977989196777
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.478897094726562
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.74188232421875
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.820282936096191
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.973362922668457
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.396154403686523
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.656463623046875
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.018399238586426
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.346035957336426
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.41033363342285
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.643608093261719
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.1988525390625
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.071487426757812
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.573795318603516
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.74983024597168
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.22142219543457
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.383243560791016
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.916214942932129
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.12167739868164
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.34355354309082
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.305628776550293
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.655614852905273
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.287664413452148
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.855281829833984
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.36960220336914
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.172161102294922
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.509862899780273
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.066084861755371
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.669489860534668
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.170327186584473
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.117935180664062
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.866554260253906
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.975375175476074
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.191144943237305
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.067508697509766
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.776571273803711
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.40768051147461
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.21350860595703
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.444406509399414
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.321998596191406
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.038328170776367
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.34961986541748
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.587334632873535
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.372434616088867
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.52978515625
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.744754791259766
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.410290718078613
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.887052536010742
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.905885696411133
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.541263580322266
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.155742645263672
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.42511749267578
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.151391983032227
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.730122566223145
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.9397554397583
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.086751937866211
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.45026683807373
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.088260650634766
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.729387283325195
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.360651016235352
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.040955543518066
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.234737396240234
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.833898544311523
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.692415237426758
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.065410614013672
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.876213073730469
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.678620338439941
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.59424877166748
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.487971305847168
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.224004745483398
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.106325149536133
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.733144760131836
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.812711715698242
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.556236267089844
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.552383422851562
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.544214248657227
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.812040328979492
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.417679786682129
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.617985725402832
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.342336654663086
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.011491775512695
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.192062377929688
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.959514617919922
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.101816177368164
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.002028465270996
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 2,
            "error": 11.619172096252441
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.64893341064453
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.616140365600586
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.887675285339355
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 2,
            "error": 12.41215705871582
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.932882308959961
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 2,
            "error": 17.496665954589844
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 2,
            "error": 14.898544311523438
        },
        "lm_head": {
            "bit_width": 2,
            "error": 14.314414024353027
        }
    },
    "average_bit_width": 2.0913705583756346,
    "error_threshold": 10,
    "min_quantile": 0.05,
    "max_quantile": 0.95,
    "quantized_model_accuracy": 0.3250441506372011
}