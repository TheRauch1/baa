{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 23.01682472229004
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.262725830078125
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.862537384033203
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 17.615371704101562
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.4603853225708
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.084365844726562
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 16.441547393798828
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 24.453121185302734
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 23.024824142456055
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.01637840270996
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 22.323055267333984
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.041606903076172
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.590457916259766
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 39.8204231262207
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.762502670288086
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.870019912719727
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.121200561523438
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.946809768676758
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.703609466552734
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.060157775878906
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.545665740966797
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.926212310791016
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.839584350585938
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.322193145751953
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.891613006591797
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.185625076293945
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.286149978637695
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.249454498291016
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 22.16183090209961
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 22.080659866333008
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.3723201751709
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.781326293945312
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.5539608001709
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.524337768554688
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.042484283447266
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.012840270996094
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.066791534423828
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.486509323120117
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.34381675720215
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.74076271057129
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.62082290649414
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.969560623168945
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.070018768310547
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.48550033569336
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.570629119873047
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.884971618652344
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.469371795654297
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.922332763671875
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.00507164001465
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.430152893066406
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 22.067581176757812
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.21031379699707
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.777950286865234
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.41988754272461
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.240816116333008
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.835721969604492
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.945587158203125
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.626651763916016
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.957550048828125
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.038745880126953
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.496578216552734
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.19001579284668
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.78151512145996
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.699356079101562
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.08480453491211
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.037025451660156
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.970205307006836
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.660648345947266
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.308738708496094
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.733869552612305
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.64399528503418
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.073654174804688
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.315784454345703
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.115203857421875
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.5629825592041
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.220104217529297
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.654708862304688
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.70960807800293
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.272016525268555
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 2,
            "error": 15.08004093170166
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.46257209777832
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.64665985107422
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.284828186035156
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.80795669555664
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.02759552001953
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 21.459482192993164
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.49620819091797
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.234567642211914
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.829341888427734
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.53435516357422
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.923316955566406
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.059886932373047
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.125507354736328
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.630918502807617
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.430667877197266
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.095510482788086
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.44591522216797
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.723108291625977
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.263648986816406
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.880985260009766
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.59489631652832
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.12825584411621
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.253459930419922
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.120040893554688
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.72353744506836
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.569534301757812
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.19679069519043
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.660829544067383
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.438167572021484
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.351276397705078
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.013193130493164
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.899078369140625
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.461467742919922
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.634906768798828
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.86168098449707
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.5180721282959
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.594654083251953
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.696205139160156
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.864980697631836
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.56851577758789
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.956377029418945
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.45722770690918
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.061140060424805
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.786296844482422
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.689476013183594
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.83770751953125
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.660358428955078
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.562280654907227
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.549686431884766
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.944271087646484
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.885162353515625
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.441131591796875
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.890605926513672
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.857900619506836
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.592727661132812
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.414047241210938
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.101802825927734
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.554168701171875
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.282089233398438
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.9475040435791
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.368947982788086
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.363250732421875
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.629911422729492
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.876630783081055
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.21859359741211
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.193878173828125
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.81985855102539
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.38365364074707
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.528606414794922
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.991710662841797
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.138513565063477
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.21891975402832
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.255260467529297
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.990097045898438
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.59747314453125
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.284032821655273
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.052379608154297
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.45257568359375
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.6773042678833
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.118194580078125
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.026304244995117
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.77105140686035
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.41164779663086
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.983182907104492
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.422521591186523
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.35478401184082
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.010433197021484
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.067798614501953
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.86941146850586
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.6390380859375
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.19896697998047
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.98593521118164
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.066155433654785
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.92633056640625
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.87398338317871
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.506366729736328
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.21633529663086
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.652132034301758
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.998111724853516
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.107073783874512
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.90260887145996
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.78692626953125
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.260967254638672
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.2510986328125
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.944427490234375
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.51338005065918
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.607583999633789
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.05078887939453
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.658903121948242
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.732418060302734
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.480960845947266
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.70937728881836
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.581897735595703
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.086326599121094
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.316869735717773
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.875762939453125
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.848188400268555
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.723474502563477
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.030813217163086
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.8409481048584
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.67314910888672
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.12565803527832
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.26922607421875
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.860681533813477
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.654348373413086
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.561330795288086
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.935924530029297
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 2,
            "error": 16.999780654907227
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.853622436523438
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.52667808532715
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.866147994995117
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.890451431274414
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.595539093017578
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.08873748779297
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 2,
            "error": 18.01228141784668
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 2,
            "error": 16.441349029541016
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 2,
            "error": 15.098344802856445
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.85641098022461
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.907609939575195
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 2,
            "error": 15.22225570678711
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.350617408752441
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 2,
            "error": 21.325035095214844
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 2,
            "error": 20.096044540405273
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 2,
            "error": 17.843582153320312
        },
        "lm_head": {
            "bit_width": 3,
            "error": 21.347640991210938
        }
    },
    "average_bit_width": 2.537777777777778,
    "error_threshold": 15,
    "min_quantile": 0.1,
    "max_quantile": 0.9,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.5029820147236977,
        "mmlu_results": {
            "overall_score": 0.5030674846625767,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.61,\"1\":0.57,\"2\":0.3650793651}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nOnce upon a time, in a world where technology had reached its zenith, humanity had become increasingly disconnected from nature and each other. People lived in sprawling metropolises, surrounded by towering skyscrapers and endless screens, but their hearts had grown cold and their souls had withered away.\n\nIn a small, forgotten village nestled in the heart of a lush forest, there lived a young girl named Ava. Ava was different from the others; she was a curious and adventurous soul,"
    }
}