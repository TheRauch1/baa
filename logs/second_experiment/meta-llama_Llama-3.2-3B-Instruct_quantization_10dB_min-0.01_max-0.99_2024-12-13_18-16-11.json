{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.4035701751709
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.24795913696289
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.438782691955566
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.89482879638672
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.49722671508789
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.316143989562988
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 16.814496994018555
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.275331497192383
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.424100875854492
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.52802848815918
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.44747543334961
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.675782203674316
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.777443885803223
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 28.16645050048828
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.936599731445312
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.214969635009766
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.66843032836914
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.984993934631348
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.21109390258789
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.632607460021973
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.541349411010742
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.243234634399414
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.139200210571289
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.959861755371094
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.302577018737793
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.599050521850586
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.755297660827637
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.486846923828125
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.996723175048828
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.134584426879883
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.24348258972168
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.350224494934082
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.925902366638184
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.834465026855469
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.695571899414062
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.959115982055664
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.746554374694824
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.598177909851074
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.760599136352539
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.24301815032959
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.932086944580078
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.646341323852539
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.274995803833008
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.11834716796875
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.230342864990234
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.37027645111084
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.986869812011719
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.16287899017334
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.769351959228516
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.804975509643555
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.658088684082031
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.63201904296875
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.632975578308105
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.903335571289062
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.515007972717285
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.49365234375
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.489334106445312
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.22736930847168
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.391836166381836
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.886137962341309
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.996025085449219
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.580251693725586
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.495296478271484
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.370809555053711
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.732386589050293
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.016529083251953
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.962685585021973
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.163829803466797
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.614683151245117
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.425634384155273
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.380342483520508
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.622297286987305
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.89761734008789
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.576624870300293
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.108528137207031
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.701985359191895
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.315953254699707
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.891374588012695
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.039281845092773
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.239646911621094
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.879274368286133
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.883110046386719
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.717233657836914
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.499979972839355
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.002918243408203
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.347827911376953
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.205278396606445
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.26722526550293
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.241816520690918
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.602651596069336
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.313469886779785
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.73806381225586
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.627745628356934
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.353474617004395
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.177322387695312
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.080670356750488
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.076333045959473
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.424248695373535
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.301322937011719
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.38476848602295
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.84471321105957
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.552274703979492
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.219525337219238
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.065202713012695
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.686270713806152
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.416622161865234
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.243325233459473
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.798507690429688
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.531801223754883
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.907861709594727
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.99830436706543
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.537983894348145
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.27946662902832
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.023984909057617
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.535541534423828
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.888538360595703
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.08833122253418
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.866710662841797
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.499445915222168
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.317476272583008
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.252019882202148
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.830556869506836
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.18124008178711
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.848284721374512
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.794029235839844
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.560985565185547
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.528388023376465
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.494465827941895
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.65510368347168
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.425264358520508
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.601286888122559
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.822525024414062
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.414529800415039
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.578121185302734
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.069575309753418
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.372106552124023
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.117053985595703
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.634485244750977
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.95682144165039
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.618353843688965
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.232013702392578
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.535292625427246
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.175172805786133
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.17476749420166
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.051580429077148
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.794673919677734
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.732266426086426
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.112041473388672
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.59932804107666
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.973536491394043
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.987489700317383
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.004884719848633
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.762386322021484
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.403952598571777
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.984657287597656
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.694808006286621
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.304672241210938
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.210671424865723
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.084672927856445
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.707083702087402
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.359443664550781
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.476303100585938
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.618729591369629
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.636882781982422
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.462873458862305
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.322868347167969
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.032196044921875
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.352371215820312
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.580904960632324
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.293487548828125
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.639535903930664
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.513659477233887
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.60524845123291
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.448495864868164
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.99858283996582
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 10.852289199829102
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.735151290893555
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.042177200317383
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.229969024658203
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.722137451171875
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.745548248291016
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.939653396606445
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.848676681518555
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.328306198120117
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.910974502563477
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.440753936767578
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.832136154174805
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.686538696289062
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.886187553405762
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.816335678100586
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.747979164123535
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.639734268188477
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.605034828186035
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.389815330505371
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.013005256652832
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 2,
            "error": 11.115913391113281
        },
        "lm_head": {
            "bit_width": 2,
            "error": 11.542709350585938
        }
    },
    "average_bit_width": 2.583756345177665,
    "error_threshold": 10,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.3022085546547386,
        "mmlu_results": {
            "overall_score": 0.24539877300613497,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.18,\"1\":0.3,\"2\":0.253968254}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 13 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIn the not too distant future, the world had come to a new era of peace. The wars had ended, and the world had found a way to live in harmony. The nations had come together, and the world had become a place of love and understanding. The technology that had been used to destroy had been used to make the world a better place. The cities had been the same, the same in and the same. The people had found a way to make the world"
    }
}