{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.112838745117188
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.270441055297852
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.156734466552734
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.114994049072266
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.216712951660156
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.595666885375977
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.15274429321289
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.934893608093262
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.37753677368164
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.877644538879395
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.05410385131836
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.606857299804688
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.22609806060791
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 31.49456214904785
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.253884315490723
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.351913452148438
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.055110931396484
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.97814655303955
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.30620765686035
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.745484352111816
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.949650764465332
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.779996871948242
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.760947227478027
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.582952499389648
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.48072624206543
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.021583557128906
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.952783584594727
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.885953903198242
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.45853328704834
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.671834945678711
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.454264640808105
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.307198524475098
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.237030029296875
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.05651569366455
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.722805976867676
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.47928524017334
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.028016090393066
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.657166481018066
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.968001365661621
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.460790634155273
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.16099739074707
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.55351734161377
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.928510665893555
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.240218162536621
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.023042678833008
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.582416534423828
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.10205841064453
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.418205261230469
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.631290435791016
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.267521858215332
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.101470947265625
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.48015785217285
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.358763694763184
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.95501136779785
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.681037902832031
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.472197532653809
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.72998332977295
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.273487091064453
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.76445198059082
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.20983123779297
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.002426147460938
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.649356842041016
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.394319534301758
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.208244323730469
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.816816329956055
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.53540325164795
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.023605346679688
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.115375518798828
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.762816429138184
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.342169761657715
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.06502914428711
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.301477432250977
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.05931282043457
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.167909622192383
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.059192657470703
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.728302001953125
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.267251968383789
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.584875106811523
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.93828582763672
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.65716552734375
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.529617309570312
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.042137145996094
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.736814498901367
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.405523300170898
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.265175819396973
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.558211326599121
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.674429893493652
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.3441162109375
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.064762115478516
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.862232208251953
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.531911849975586
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.946144104003906
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.077072143554688
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.579113006591797
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.611190795898438
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.044724464416504
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.775592803955078
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.303847312927246
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.471935272216797
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.10196304321289
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.085790634155273
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.26938819885254
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.052899360656738
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.412565231323242
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.387031555175781
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.099716186523438
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.214221954345703
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.462355613708496
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.03236198425293
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.3363037109375
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.41075325012207
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.565738677978516
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.299202919006348
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.670175552368164
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.190980911254883
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.140753746032715
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.977087020874023
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.196427345275879
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.525991439819336
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.464393615722656
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.995159149169922
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.392643928527832
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.689035415649414
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.210988998413086
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.225046157836914
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.496582984924316
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.07660484313965
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.52800750732422
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.278894424438477
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.682827949523926
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.46714973449707
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.07148265838623
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.578392028808594
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.030132293701172
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.63589859008789
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.473090171813965
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.823033332824707
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.180736541748047
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.946788787841797
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.644830703735352
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.384193420410156
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.052677154541016
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.411052703857422
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.410511016845703
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.92265510559082
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.908652305603027
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.464485168457031
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.411935806274414
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.412975311279297
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.151476860046387
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.789485931396484
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.952577590942383
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.974039077758789
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.60012435913086
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.658058166503906
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.685224533081055
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.950705528259277
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.225996017456055
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.50668716430664
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.85498332977295
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.690439224243164
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.870616912841797
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.108137130737305
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.096755027770996
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.168597221374512
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.19248390197754
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.743285179138184
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.755136489868164
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.76616096496582
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.754993438720703
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.861732482910156
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.727413177490234
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.897672653198242
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.678977966308594
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.609302520751953
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.003130912780762
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.30317497253418
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.122861862182617
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.627861976623535
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.905654907226562
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.640161514282227
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.475875854492188
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.2874755859375
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.85637664794922
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.6021089553833
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.245776176452637
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.2841739654541
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.778497695922852
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.385470390319824
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.764284133911133
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.969711303710938
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.60688304901123
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.231786727905273
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.653047561645508
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.030801773071289
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.600906372070312
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.061328887939453
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.819358825683594
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.776473045349121
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.559770584106445
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.149641036987305
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.806999206542969
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.983375549316406
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.295419692993164
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.49438190460205
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.967596054077148
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.647638320922852
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.337230682373047
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.51528549194336
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.216660499572754
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.863794326782227
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.367097854614258
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.63432502746582
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.732170104980469
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.159360885620117
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.369997024536133
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 3,
            "error": 16.870983123779297
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.722772598266602
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.766266822814941
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.556468963623047
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.666015625
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.166677474975586
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.529497146606445
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.1394100189209
        },
        "lm_head": {
            "bit_width": 3,
            "error": 15.817452430725098
        }
    },
    "average_bit_width": 2.8666666666666667,
    "error_threshold": 12,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.43695834498182834,
        "mmlu_results": {
            "overall_score": 0.26380368098159507,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.24,\"1\":0.26,\"2\":0.2857142857}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\n**The small town of Willowdale**\n\nIt was a chilly winter morning in the small town of Willowdale, and the residents were bustling about, preparing for the annual WinterFest celebration. The townspeople were known for their warmth and kindness, and this year was shaping up to be a particularly special one.\n\nEmma, a young girl with a big heart, had been planning a surprise party for her elderly neighbor, Mrs. Thompson, who had been living alone since her husband passed"
    }
}