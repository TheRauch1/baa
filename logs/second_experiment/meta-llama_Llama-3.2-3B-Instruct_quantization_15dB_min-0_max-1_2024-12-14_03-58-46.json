{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.959537506103516
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.05679702758789
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.677978515625
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 5,
            "error": 17.836803436279297
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.37654972076416
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.994032859802246
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 5,
            "error": 18.05299949645996
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 17.623985290527344
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.766704559326172
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.772056579589844
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 5,
            "error": 17.51285743713379
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.634492874145508
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 5,
            "error": 20.54020881652832
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 8,
            "error": 21.493558883666992
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.07437515258789
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.829580307006836
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.096479415893555
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.702547073364258
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.379846572875977
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.290494918823242
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 5,
            "error": 18.449573516845703
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 3,
            "error": 17.327272415161133
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.907148361206055
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.58949851989746
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.464975357055664
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.186786651611328
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.436870574951172
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.62354850769043
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.55550193786621
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 16.997600555419922
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.56412696838379
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.98276138305664
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 4,
            "error": 18.21363067626953
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.110153198242188
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.17743682861328
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.296974182128906
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.43094253540039
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.83905792236328
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.6013240814209
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 4,
            "error": 18.734878540039062
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.238439559936523
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.933866500854492
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.179194450378418
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.353899002075195
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.76862144470215
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.915857315063477
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 4,
            "error": 18.864532470703125
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.341096878051758
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.56548023223877
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 16.85958480834961
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.880935668945312
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 4,
            "error": 19.268911361694336
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.703079223632812
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 4,
            "error": 19.00726890563965
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.506692886352539
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.173430442810059
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.258800506591797
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.519061088562012
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.381620407104492
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.714542388916016
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 4,
            "error": 18.89056968688965
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.723026275634766
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.026023864746094
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.444730758666992
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 16.153682708740234
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.06212615966797
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.9429931640625
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 4,
            "error": 18.343029022216797
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.982934951782227
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.263931274414062
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.475439071655273
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.031886100769043
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 4,
            "error": 19.272275924682617
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.23540496826172
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.545639038085938
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.843549728393555
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.044099807739258
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 3,
            "error": 16.810447692871094
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.31009292602539
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.9529972076416
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 5,
            "error": 18.90200424194336
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.999910354614258
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.228851318359375
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.366783142089844
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.85581398010254
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.992023468017578
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.350297927856445
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 5,
            "error": 17.33672332763672
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.878551483154297
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.02859878540039
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.358654022216797
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.81534194946289
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.729907989501953
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.357255935668945
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.125484466552734
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.284233093261719
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 5,
            "error": 21.2587833404541
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.57275390625
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.313268661499023
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.332707405090332
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.398359298706055
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.29232406616211
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.650506973266602
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.313270568847656
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.384025573730469
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.214496612548828
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.349918365478516
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.578826904296875
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.52541732788086
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.387954711914062
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.8323335647583
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 5,
            "error": 17.718589782714844
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.038774490356445
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.15805435180664
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.93208122253418
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.237512588500977
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.880367279052734
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.98763656616211
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.519716262817383
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.167057037353516
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.684717178344727
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.568904876708984
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 5,
            "error": 19.92634391784668
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.880819320678711
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.03704071044922
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 5,
            "error": 16.741012573242188
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.1550235748291
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.211193084716797
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.9998779296875
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.238759994506836
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.868110656738281
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.914514541625977
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.726255416870117
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.642087936401367
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.993698120117188
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.7721004486084
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 5,
            "error": 17.865018844604492
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.489633560180664
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.343534469604492
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.4356050491333
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.641990661621094
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.18594741821289
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.172958374023438
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 5,
            "error": 21.28140640258789
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.937536239624023
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.16908073425293
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 5,
            "error": 20.26876449584961
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.08464813232422
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.796024322509766
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.721418380737305
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.503417015075684
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.428197860717773
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.897859573364258
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.71042537689209
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.20904541015625
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.130340576171875
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.08707046508789
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.323596954345703
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.63136100769043
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.005271911621094
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 5,
            "error": 19.583980560302734
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 4,
            "error": 19.870649337768555
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.74969482421875
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 15.98739242553711
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 5,
            "error": 20.646503448486328
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.87043571472168
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.490829467773438
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 5,
            "error": 21.051658630371094
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.178796768188477
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.583087921142578
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.16075897216797
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.48648738861084
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.628433227539062
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.59685707092285
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.80696678161621
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.498023986816406
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.247737884521484
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 16.509178161621094
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.06303596496582
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.678085327148438
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 4,
            "error": 17.255512237548828
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.562600135803223
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.173377990722656
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 4,
            "error": 19.769624710083008
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 15.445819854736328
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 5,
            "error": 21.346553802490234
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.99736213684082
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 4,
            "error": 18.69028663635254
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 4,
            "error": 15.501516342163086
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 15.011726379394531
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 15.29810905456543
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 15.099268913269043
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 5,
            "error": 16.268558502197266
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.27299690246582
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.989601135253906
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 5,
            "error": 18.85580825805664
        },
        "lm_head": {
            "bit_width": 4,
            "error": 19.463211059570312
        }
    },
    "average_bit_width": 4.157360406091371,
    "error_threshold": 15,
    "min_quantile": 0,
    "max_quantile": 1,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.42978287205293075,
        "mmlu_results": {
            "overall_score": 0.3006134969325153,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.18,\"1\":0.34,\"2\":0.3650793651}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIn a small village nestled in the rolling hills of a rural town, there lived a young girl named Maya. Maya was a bright and curious 10-year-old who loved to explore the world around her. She spent most of her days playing in the nearby forest, collecting leaves, and watching the wildlife. But Maya had a secret dream - to become a scientist and make a discovery that would change the world.\n\nOne day, while wandering deeper into the forest than she had ever gone"
    }
}