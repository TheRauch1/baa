{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "original_model_accuracy": 0.4633191733091499,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.668914794921875
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.100831985473633
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.983922958374023
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.742534637451172
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.31985855102539
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.174272537231445
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.888702392578125
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.0415096282959
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 28.016326904296875
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.86767578125
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 4,
            "error": 26.005626678466797
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.217077255249023
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.594579696655273
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 28.024322509765625
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.125823974609375
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 24.64480209350586
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.03647804260254
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.753782272338867
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.19647789001465
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.45915412902832
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.86313819885254
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.764362335205078
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.121910095214844
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.07848358154297
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.15470314025879
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.24082374572754
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.565475463867188
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.456045150756836
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 3,
            "error": 27.223356246948242
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.44645881652832
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.351696014404297
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.431377410888672
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.634937286376953
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.632801055908203
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.47360610961914
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.98444938659668
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.291147232055664
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.739261627197266
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.463912963867188
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.957082748413086
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.78927993774414
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.564992904663086
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.06837272644043
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.8468017578125
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.12364959716797
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.1898193359375
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.689781188964844
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.05666732788086
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.535959243774414
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.521282196044922
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.713489532470703
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.05160903930664
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.493995666503906
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.734663009643555
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.452592849731445
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.277587890625
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.324628829956055
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.531475067138672
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.39188575744629
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.69607162475586
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.840883255004883
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.513893127441406
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.281768798828125
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.09229850769043
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 24.998991012573242
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.410659790039062
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.720369338989258
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.006240844726562
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.525104522705078
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.206134796142578
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.94724464416504
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 24.81102752685547
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.54205322265625
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.401290893554688
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.14691734313965
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.690824508666992
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.207855224609375
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.167924880981445
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.477642059326172
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.193830490112305
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.666929244995117
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.004310607910156
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.738407135009766
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.39875602722168
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.687782287597656
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.659282684326172
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.567794799804688
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.10845947265625
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.239534378051758
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.640867233276367
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.165935516357422
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.437482833862305
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 24.004714965820312
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.049108505249023
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.85594940185547
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.492778778076172
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.157468795776367
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.220844268798828
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.43503189086914
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 24.067920684814453
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.972679138183594
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.187503814697266
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.457149505615234
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.06422233581543
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.44666290283203
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.019384384155273
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.15477752685547
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.95130157470703
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.081552505493164
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.02798080444336
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.993133544921875
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.32868003845215
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.710803985595703
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.044422149658203
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.178199768066406
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.745012283325195
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.929683685302734
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.741748809814453
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.182222366333008
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.719680786132812
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.27773666381836
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.151254653930664
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.984107971191406
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.66242218017578
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.629474639892578
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.288711547851562
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.092880249023438
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.73367691040039
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.14747428894043
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.17681312561035
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.433027267456055
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.648963928222656
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.11646270751953
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.438411712646484
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.15416145324707
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.967041015625
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.05055046081543
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.422470092773438
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.771427154541016
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.368301391601562
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.612144470214844
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.881078720092773
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.30637550354004
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.73680877685547
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.717002868652344
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.551591873168945
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.348485946655273
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.824989318847656
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.059797286987305
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.406784057617188
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.50156021118164
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.246370315551758
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.50002670288086
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.12478256225586
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.82857894897461
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.551776885986328
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.69849395751953
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.84135627746582
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.4359130859375
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.42963409423828
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.08006477355957
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.063190460205078
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.832542419433594
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.031490325927734
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.958911895751953
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.22901153564453
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.671913146972656
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.03314781188965
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.21966552734375
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.079505920410156
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.452974319458008
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.43843650817871
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.565937042236328
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.09561538696289
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.669239044189453
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.602266311645508
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.94870376586914
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.543582916259766
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.542938232421875
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.184961318969727
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 4,
            "error": 26.423377990722656
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.6342830657959
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.584144592285156
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.27799415588379
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.754817962646484
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.887252807617188
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.482955932617188
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.34086799621582
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 4,
            "error": 25.598281860351562
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.997711181640625
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.665874481201172
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.879398345947266
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 4,
            "error": 26.297657012939453
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.27410888671875
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 24.829256057739258
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 22.26632308959961
        },
        "lm_head": {
            "bit_width": 3,
            "error": 21.66766929626465
        }
    },
    "average_bit_width": 3.517766497461929,
    "error_threshold": 20,
    "min_quantile": 0.05,
    "max_quantile": 0.95,
    "quantized_model_accuracy": 0.4530571333110591
}