{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.909961700439453
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 20.307090759277344
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.900239944458008
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.369697570800781
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.32676887512207
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.091827392578125
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 13.326011657714844
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.126527786254883
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.860136032104492
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.703095436096191
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.75290298461914
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.834485054016113
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.524258613586426
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 32.4927864074707
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.674617767333984
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.774646759033203
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.794378280639648
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.192416191101074
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.995771408081055
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.33551025390625
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.869039535522461
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.360952377319336
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.576005935668945
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.928049087524414
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.110433578491211
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.443465232849121
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.491076469421387
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.43174934387207
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.700923919677734
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.852293014526367
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.39888858795166
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.266828536987305
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.141024589538574
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.630716323852539
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.510566711425781
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.561145782470703
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.804401397705078
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.741838455200195
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.909639358520508
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.492043495178223
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.726794242858887
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.577733993530273
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.575618743896484
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.45322036743164
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.15981388092041
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.489248275756836
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.267026901245117
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.955787658691406
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.587482452392578
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 19.0560359954834
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.2473087310791
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.639275550842285
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.790592193603516
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.29331111907959
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.399303436279297
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.275598526000977
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.917926788330078
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.04563331604004
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.483404159545898
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.0230073928833
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.428885459899902
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.448265075683594
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.353684425354004
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.744657516479492
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.671772003173828
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.387629508972168
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.208849906921387
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.582579612731934
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.49361515045166
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.220745086669922
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.5084228515625
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.403003692626953
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.992082595825195
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.869345664978027
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.578535079956055
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.637636184692383
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.262032508850098
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.71005630493164
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 19.17906379699707
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.208128929138184
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.06043243408203
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.470815658569336
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.6904878616333
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.353952407836914
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.207178115844727
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.303226470947266
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 2,
            "error": 12.479790687561035
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.4345703125
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.82967758178711
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.636214256286621
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.213167190551758
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.9118709564209
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.761001586914062
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.955013275146484
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.396008491516113
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.87938117980957
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.133077621459961
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.266054153442383
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.032100677490234
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.810110092163086
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.067837715148926
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.672075271606445
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.915695190429688
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.044569969177246
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.47757625579834
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.613996505737305
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.875445365905762
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.883865356445312
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.652538299560547
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.526081085205078
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.961197853088379
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.373748779296875
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.245561599731445
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.668956756591797
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.01429557800293
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.937210083007812
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.556721687316895
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.677746772766113
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.248002052307129
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.3166561126709
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.949323654174805
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.050568580627441
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.304643630981445
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.280740737915039
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.568350791931152
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.322345733642578
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.787110328674316
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.376070022583008
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.180376052856445
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.659343719482422
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.979732513427734
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.57016372680664
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.187328338623047
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.087526321411133
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.939531326293945
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 2,
            "error": 11.022832870483398
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.101455688476562
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.054649353027344
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.7084379196167
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.48348617553711
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.212244033813477
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.457396507263184
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.280009269714355
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.25004005432129
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.393506050109863
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.504823684692383
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.467241287231445
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.47905731201172
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.761542320251465
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.376795768737793
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 17.097183227539062
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.007793426513672
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.464468002319336
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.143760681152344
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.409137725830078
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.16623306274414
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.741622924804688
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.103991508483887
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.16265869140625
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.402856826782227
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.099885940551758
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.6560697555542
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.36600112915039
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.041751861572266
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.176783561706543
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 2,
            "error": 13.90921688079834
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.737764358520508
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.038530349731445
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.81668758392334
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.650388717651367
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.590163230895996
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.281614303588867
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.31944465637207
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 2,
            "error": 11.169962882995605
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.745172500610352
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.821468353271484
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.61416244506836
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.609596252441406
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 2,
            "error": 10.909536361694336
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.730596542358398
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 2,
            "error": 12.490697860717773
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.690484046936035
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.22461700439453
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.943379402160645
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.081254959106445
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.252068519592285
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.831401824951172
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 2,
            "error": 13.870100021362305
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 2,
            "error": 11.726244926452637
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.532289505004883
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.491069793701172
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 2,
            "error": 10.691360473632812
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 2,
            "error": 13.080643653869629
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.6209135055542
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 2,
            "error": 17.292633056640625
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 2,
            "error": 14.844615936279297
        },
        "lm_head": {
            "bit_width": 2,
            "error": 14.670143127441406
        }
    },
    "average_bit_width": 2.0862944162436547,
    "error_threshold": 10,
    "min_quantile": 0.05,
    "max_quantile": 0.95,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.35830770664430156,
        "mmlu_results": {
            "overall_score": 0.2852760736196319,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.31,\"1\":0.32,\"2\":0.2380952381}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 13 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nOnce upon a time, in a bustling city, there was a small, rundown restaurant that had been on the verge of closing due to the economic downturn. The owner, a kind-hearted but weary woman named Maria, was on the verge of giving up. She had poured her heart and soul into the restaurant, but the lack of customers and the harsh economic times had taken its toll.\n\nOne day, while sitting in her restaurant, lost in thought, Maria couldn't help but notice"
    }
}