{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "original_model_accuracy": 0.4633191733091499,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.203710556030273
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.035258293151855
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.178375244140625
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.787277221679688
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.518924713134766
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.401253700256348
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 16.927936553955078
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.067150115966797
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.596817016601562
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.627248764038086
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.266557693481445
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.070560455322266
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.852869033813477
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 24.396812438964844
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.85259437561035
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.234134674072266
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.521160125732422
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.623329162597656
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.417068481445312
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.389101028442383
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.23262596130371
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.2813720703125
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.277956008911133
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.123194694519043
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.333720207214355
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.040250778198242
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.480512619018555
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.143360137939453
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.079011917114258
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.273653030395508
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.233696937561035
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.134347915649414
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.390785217285156
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.494029998779297
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.321399688720703
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.49978256225586
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.494688034057617
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.655841827392578
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.265918731689453
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.719579696655273
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.01678466796875
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.263179779052734
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.898338317871094
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.90615463256836
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.299360275268555
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.093368530273438
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.39892578125
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.255599975585938
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.359268188476562
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.510135650634766
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.886171340942383
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.75379180908203
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.296436309814453
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.398544311523438
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.60335636138916
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.10840606689453
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.973342895507812
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.039731979370117
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.381011962890625
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.53350830078125
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.44220542907715
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.647235870361328
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.098011016845703
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.831588745117188
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.447595596313477
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.023269653320312
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.491596221923828
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.545133590698242
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.666149139404297
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.02231788635254
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.807472229003906
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.35887908935547
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 17.061838150024414
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.022409439086914
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.621261596679688
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.789061546325684
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.975627899169922
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.390567779541016
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.029040336608887
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.304832458496094
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 19.462360382080078
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.409887313842773
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.772464752197266
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.174034118652344
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.366914749145508
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.75629234313965
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.268798828125
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.923095703125
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.618316650390625
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.651815414428711
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.93633270263672
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.215789794921875
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.826581954956055
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.45936107635498
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.607391357421875
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.64722442626953
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.117069244384766
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.050704956054688
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.72845458984375
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.828392028808594
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.38493537902832
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 19.024959564208984
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.706666946411133
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.103721618652344
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.2852840423584
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.70917320251465
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.5108699798584
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.46710968017578
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 19.89889907836914
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 19.370323181152344
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.068405151367188
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.15731430053711
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.688610076904297
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.542991638183594
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.304393768310547
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.63491439819336
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.451953887939453
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.562273025512695
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.072227478027344
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.638137817382812
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.711870193481445
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.50284194946289
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 4,
            "error": 19.84320068359375
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.223125457763672
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.50058364868164
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.165884017944336
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.791921615600586
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.121557235717773
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.23832893371582
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 19.916015625
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.010852813720703
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.545507431030273
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.017610549926758
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.256330490112305
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.750286102294922
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.96834945678711
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.752059936523438
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.00496482849121
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.040446281433105
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.207971572875977
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.518882751464844
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.034778594970703
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.925016403198242
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.646263122558594
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.339324951171875
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.48454475402832
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.286544799804688
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.412437438964844
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.993953704833984
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.66352081298828
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.39290428161621
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.919456481933594
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.443042755126953
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.06769371032715
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.448720932006836
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 18.57339859008789
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.891170501708984
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.047195434570312
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.0241756439209
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.369205474853516
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.971086502075195
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 18.752384185791016
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.977277755737305
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.281986236572266
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.699993133544922
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.585186004638672
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.598386764526367
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.960386276245117
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.011873245239258
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.986957550048828
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.212018966674805
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.279159545898438
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.826751708984375
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.376382827758789
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.612335205078125
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.364465713500977
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 19.471498489379883
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.5642032623291
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.431175231933594
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.110441207885742
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.691619873046875
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.487422943115234
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 19.14148712158203
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 17.4122371673584
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 19.527442932128906
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.147140502929688
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.357519149780273
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 18.191879272460938
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.806384086608887
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.572681427001953
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.90386390686035
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.38567352294922
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.214263916015625
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 18.098461151123047
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.641422271728516
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 18.43368911743164
        },
        "lm_head": {
            "bit_width": 3,
            "error": 18.552196502685547
        }
    },
    "average_bit_width": 3.33502538071066,
    "error_threshold": 15,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_accuracy": 0.4299078802921102
}