{
    "model_name": "meta-llama/Llama-3.2-3B-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.747882843017578
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.268537521362305
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.066492080688477
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.563587188720703
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 4,
            "error": 23.106576919555664
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.93609619140625
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 4,
            "error": 23.351306915283203
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.14409828186035
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.66838836669922
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.166250228881836
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.03487205505371
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.6390380859375
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 4,
            "error": 22.408458709716797
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 28.16645050048828
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.819778442382812
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.987585067749023
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.28802490234375
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.593475341796875
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.82608413696289
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.231338500976562
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.1333065032959
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.751361846923828
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.271461486816406
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.572219848632812
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.914283752441406
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 4,
            "error": 23.221073150634766
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.385116577148438
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.118480682373047
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.866535186767578
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.238235473632812
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.810256958007812
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.002330780029297
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.863262176513672
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.465373992919922
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.32652473449707
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.40020179748535
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.4384765625
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.202960968017578
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.30358123779297
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.19289207458496
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.552955627441406
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.28693389892578
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.800273895263672
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.871631622314453
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.90895652770996
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.10335922241211
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.94540023803711
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.76156997680664
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.38993263244629
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.414806365966797
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.803508758544922
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.176616668701172
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.271663665771484
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.88486671447754
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 4,
            "error": 22.142578125
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.084091186523438
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.901506423950195
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.035449981689453
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.90850067138672
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 5,
            "error": 24.733322143554688
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.988256454467773
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 4,
            "error": 22.18316650390625
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.117488861083984
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.873411178588867
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.545936584472656
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.66575813293457
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 5,
            "error": 24.844646453857422
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.120182037353516
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 4,
            "error": 22.248886108398438
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.043088912963867
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.70847511291504
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.357818603515625
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.581981658935547
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 5,
            "error": 24.415760040283203
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.062658309936523
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 4,
            "error": 22.3428955078125
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.981834411621094
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.27971076965332
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.63810920715332
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.825428009033203
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 5,
            "error": 25.80640983581543
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.871192932128906
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 4,
            "error": 22.308053970336914
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.104707717895508
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 4,
            "error": 25.84075164794922
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.386674880981445
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.804893493652344
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 5,
            "error": 24.166086196899414
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.219398498535156
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 4,
            "error": 22.17686653137207
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.956727981567383
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.093711853027344
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.57854461669922
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.023914337158203
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 5,
            "error": 25.010435104370117
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.996002197265625
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.70083999633789
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.074291229248047
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.216442108154297
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 4,
            "error": 26.565345764160156
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.47707176208496
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 5,
            "error": 25.388492584228516
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.173503875732422
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.69867706298828
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.288848876953125
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.26004981994629
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.129974365234375
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.412273406982422
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.15612030029297
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.856353759765625
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.61859703063965
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.193931579589844
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.173486709594727
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.251041412353516
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.171741485595703
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.498153686523438
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.038442611694336
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.470439910888672
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.113861083984375
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.173168182373047
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.489078521728516
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.4445858001709
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 5,
            "error": 26.118106842041016
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.799718856811523
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.415719985961914
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.172704696655273
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 4,
            "error": 25.400955200195312
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.597248077392578
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.217805862426758
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.095300674438477
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.55767059326172
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.441736221313477
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.034223556518555
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.241531372070312
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.32533836364746
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.997005462646484
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.748355865478516
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.629791259765625
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.59071922302246
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.26551628112793
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.094707489013672
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.592247009277344
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.843902587890625
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.76715850830078
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.0042724609375
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.411104202270508
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.36530876159668
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.012060165405273
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.590322494506836
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.566843032836914
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.580284118652344
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 4,
            "error": 23.602508544921875
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.365894317626953
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.067533493041992
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.45389175415039
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.130168914794922
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.855466842651367
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.854093551635742
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 4,
            "error": 23.722450256347656
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.296388626098633
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.96673011779785
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 4,
            "error": 25.30887222290039
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.825847625732422
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.24541473388672
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.015918731689453
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.293712615966797
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.63996696472168
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 20.951942443847656
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 4,
            "error": 25.580167770385742
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 4,
            "error": 24.4406795501709
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.14791488647461
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.070470809936523
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.51229476928711
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 4,
            "error": 22.078771591186523
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.640254974365234
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.051902770996094
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 4,
            "error": 26.05882453918457
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.57893943786621
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.847251892089844
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.651660919189453
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 4,
            "error": 23.357763290405273
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.536561965942383
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 4,
            "error": 25.627750396728516
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 4,
            "error": 23.839950561523438
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 5,
            "error": 25.684226989746094
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.121822357177734
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.720401763916016
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.712993621826172
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 4,
            "error": 22.500856399536133
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.45606231689453
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.848262786865234
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.159656524658203
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.221500396728516
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 4,
            "error": 24.441303253173828
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.399316787719727
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 4,
            "error": 25.067951202392578
        },
        "lm_head": {
            "bit_width": 4,
            "error": 25.542966842651367
        }
    },
    "average_bit_width": 3.8883248730964466,
    "error_threshold": 20,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.4662659584381698,
        "mmlu_results": {
            "overall_score": 0.42024539877300615,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.52,\"1\":0.44,\"2\":0.3253968254}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Dec 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nOnce upon a time, in a world where the sun shone bright and the air was crisp and clean, there lived a young girl named Aria. She lived in a small village surrounded by lush green forests and sparkling rivers, where everyone knew and loved one another.\n\nAria was a kind and gentle soul, with a heart full of compassion and a smile that could light up the darkest of rooms. She spent her days helping her neighbors, tending to the village gardens,"
    }
}