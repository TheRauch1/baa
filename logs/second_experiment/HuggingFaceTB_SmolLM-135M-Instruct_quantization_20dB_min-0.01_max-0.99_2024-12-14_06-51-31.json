{
    "model_name": "HuggingFaceTB/SmolLM-135M-Instruct",
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 4,
            "error": 24.024940490722656
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 4,
            "error": 26.09720230102539
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.809188842773438
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 24.221284866333008
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.874479293823242
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 5,
            "error": 26.188331604003906
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 4,
            "error": 26.23908042907715
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.404115676879883
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.717792510986328
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.54695701599121
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.79230308532715
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.610807418823242
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.494537353515625
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.839427947998047
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.76786231994629
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.19504165649414
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.998519897460938
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.17427635192871
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.516422271728516
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.173723220825195
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.73296356201172
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.174728393554688
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.630348205566406
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.121557235717773
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.44920539855957
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.13577651977539
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.0014705657959
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 22.793970108032227
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.279014587402344
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.143051147460938
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.540653228759766
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.45206069946289
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.691730499267578
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.047340393066406
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.312496185302734
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.44310760498047
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.704875946044922
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.84051513671875
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.219146728515625
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.559001922607422
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.243247985839844
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.531829833984375
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.32282066345215
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.707199096679688
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.84868049621582
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.3050537109375
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.49747085571289
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.23990821838379
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.527400970458984
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.530380249023438
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.188297271728516
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.65043067932129
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.610389709472656
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.456871032714844
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.226282119750977
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 22.592790603637695
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.812273025512695
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.645740509033203
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.486900329589844
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.390771865844727
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.5972957611084
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.239030838012695
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.939796447753906
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.361785888671875
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 5,
            "error": 26.177289962768555
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.378341674804688
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.021587371826172
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.26929473876953
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.26146125793457
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.545974731445312
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.172649383544922
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.10418128967285
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.020858764648438
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.74860954284668
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 4,
            "error": 23.386032104492188
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.180862426757812
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.470901489257812
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.77124786376953
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.112777709960938
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.648902893066406
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.095617294311523
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.69139862060547
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.224634170532227
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 31.916532516479492
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.38863182067871
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.982746124267578
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.685199737548828
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.225093841552734
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.77468490600586
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.659976959228516
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.865062713623047
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.406017303466797
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.01291275024414
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.477272033691406
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.4857177734375
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.336217880249023
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.202075958251953
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.528141021728516
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.743915557861328
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.724056243896484
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 4,
            "error": 22.010169982910156
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.21341323852539
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 4,
            "error": 20.987932205200195
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.13461685180664
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.068592071533203
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.618946075439453
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 4,
            "error": 23.28635025024414
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.91077995300293
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 5,
            "error": 26.17388153076172
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.423303604125977
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.098691940307617
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.075294494628906
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.704349517822266
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.61475944519043
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.343965530395508
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.19048500061035
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.435474395751953
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.347755432128906
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.137165069580078
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.79932403564453
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.803775787353516
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.92975616455078
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.697044372558594
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.588397979736328
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.38352394104004
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.32457733154297
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.498851776123047
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.10927391052246
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.421859741210938
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.645339965820312
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.775115966796875
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.245243072509766
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.038904190063477
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.156307220458984
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.854171752929688
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 21.37151527404785
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.441482543945312
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.00761604309082
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.411067962646484
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.080970764160156
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.74918556213379
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.322864532470703
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.81296157836914
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.438003540039062
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.31464385986328
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.6567440032959
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.386497497558594
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.812618255615234
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.066383361816406
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.75383186340332
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.080053329467773
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 4,
            "error": 22.18400764465332
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.77302360534668
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.545799255371094
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.297433853149414
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.121597290039062
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.620813369750977
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.234874725341797
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.848955154418945
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.43710708618164
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.531055450439453
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.9334659576416
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.894439697265625
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 5,
            "error": 26.21027946472168
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.388288497924805
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.581100463867188
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.212963104248047
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.34284782409668
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 4,
            "error": 22.01795196533203
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 4,
            "error": 23.503400802612305
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.496978759765625
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.05076026916504
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.51614761352539
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.419170379638672
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.316757202148438
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.34294891357422
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.88011360168457
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.20646858215332
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.681625366210938
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.688915252685547
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.34159278869629
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.282997131347656
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 4,
            "error": 21.221561431884766
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 4,
            "error": 21.006784439086914
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.210582733154297
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 22.157516479492188
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.67719268798828
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.533912658691406
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.826374053955078
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 5,
            "error": 26.349075317382812
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 4,
            "error": 23.267114639282227
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.8322696685791
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.73289680480957
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 4,
            "error": 21.636343002319336
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.39044189453125
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 4,
            "error": 21.337169647216797
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 4,
            "error": 20.752803802490234
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 4,
            "error": 22.933237075805664
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 4,
            "error": 20.796415328979492
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.133255004882812
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 4,
            "error": 23.90294647216797
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 4,
            "error": 22.257362365722656
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 2,
            "error": 21.367839813232422
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 5,
            "error": 25.514217376708984
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 4,
            "error": 20.14923095703125
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 5,
            "error": 26.323837280273438
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.541976928710938
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 5,
            "error": 26.291913986206055
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 4,
            "error": 21.938798904418945
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.02167320251465
        },
        "lm_head": {
            "bit_width": 4,
            "error": 25.170995712280273
        }
    },
    "average_bit_width": 4.042654028436019,
    "error_threshold": 20,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.4063926940639269,
        "mmlu_results": {
            "overall_score": 0.29754601226993865,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.3,\"1\":0.3,\"2\":0.2936507937}}"
        },
        "sanity_check_string": "user\nTell a short story of humanity with happy ending\nassistant\nThe last thing I remember is that I looked in the mirror, wondering what I would be like without it. My eyes were cloudy, my nose was smeared with dirt, my hair was dull, my skin was cracked, and my stomach was full.\n\nBut, to my surprise, that's exactly what happened to me. A group of humans, dressed in stylish attire, arrived in my life, who were demanding the best of life. They told me they would like"
    }
}