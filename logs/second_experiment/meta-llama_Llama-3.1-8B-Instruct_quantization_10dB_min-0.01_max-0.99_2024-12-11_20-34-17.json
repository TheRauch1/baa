{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "original_model_benchmarks": {
        "wikitext_accuracy": 0.5299508376688463,
        "mmlu_results": {
            "overall_score": 0.6165644171779141,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.67,\"1\":0.73,\"2\":0.4841269841}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\nuser\n\nTell a short story of humanity with happy endingassistant\n\nIn the year 2154, the world had finally reached a point of perfect harmony. After centuries of wars, conflicts, and environmental disasters, humanity had come together to form a united global government, dedicated to the well-being of all people and the planet.\n\nThe city of New Eden, a marvel of modern technology, was the capital of this new world order. Towering skyscrapers made of sustainable materials stretched towards the sky, their exteriors covered in lush greenery and"
    },
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.097234725952148
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.19271183013916
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.320127487182617
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 11.332863807678223
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.985475540161133
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.556482315063477
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 10.797063827514648
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.939565658569336
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.326383590698242
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.952857971191406
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.352324485778809
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.829011917114258
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.36848258972168
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 31.429115295410156
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.22300910949707
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.68249225616455
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.13400936126709
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.904874801635742
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.412918090820312
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.858616828918457
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.992585182189941
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.831799507141113
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.799869537353516
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.599414825439453
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.649169921875
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.197772979736328
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.019754409790039
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.909635543823242
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.476377487182617
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.65330696105957
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.353055953979492
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.605426788330078
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.917594909667969
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.0695219039917
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.73082447052002
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.483736038208008
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 13.104676246643066
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.602218627929688
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.870047569274902
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.044538497924805
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.219467163085938
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.6055908203125
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.855599403381348
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.211024284362793
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.063547134399414
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.310586929321289
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.696950912475586
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.484901428222656
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.65877628326416
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.318979263305664
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.158968925476074
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.435253143310547
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.254384994506836
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.566805839538574
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.73048210144043
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.475302696228027
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.82504653930664
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.34674072265625
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.595983505249023
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.675506591796875
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.687110900878906
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.710982322692871
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.410160064697266
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.219758033752441
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.823099136352539
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.51182746887207
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.381964683532715
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.744760513305664
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.821223258972168
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.362293243408203
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.110405921936035
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.435455322265625
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.885272979736328
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.681662559509277
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.69087028503418
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.774961471557617
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.272761344909668
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.684989929199219
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.006509780883789
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 16.513324737548828
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 10.607404708862305
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.695456504821777
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.73885726928711
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.352893829345703
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 14.306255340576172
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 14.494913101196289
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.57425308227539
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.733680725097656
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.779926300048828
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.86087417602539
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.55557632446289
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.935113906860352
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.689955711364746
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.497575759887695
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 10.9700345993042
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.158649444580078
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.872308731079102
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.29439926147461
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.12185287475586
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.751128196716309
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.041390419006348
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.570470809936523
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.197937965393066
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.502193450927734
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.357528686523438
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.978529930114746
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.64368724822998
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.374536514282227
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 11.815489768981934
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 2,
            "error": 12.485725402832031
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.526369094848633
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.492424011230469
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.289142608642578
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.173659324645996
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.211478233337402
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.434395790100098
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.823054313659668
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.321036338806152
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.504945755004883
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.478233337402344
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.575769424438477
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.343631744384766
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.658037185668945
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.855438232421875
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.331221580505371
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.442816734313965
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.039985656738281
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.11941146850586
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.441650390625
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.823297500610352
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.104022026062012
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.175369262695312
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.494805335998535
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.100602149963379
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.140653610229492
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.52048397064209
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.942028999328613
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.76980972290039
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.053505897521973
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.609679222106934
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.415639877319336
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.502577781677246
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.297466278076172
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.511029243469238
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.490885734558105
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.012800216674805
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.441587448120117
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.401408195495605
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.005119323730469
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.166170120239258
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.889602661132812
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.540033340454102
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.067625045776367
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.563304901123047
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.655569076538086
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.63821029663086
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.098417282104492
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.237512588500977
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.100845336914062
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.946451187133789
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.585824966430664
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.688228607177734
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.605420112609863
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.21802043914795
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.253217697143555
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.09556770324707
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.812773704528809
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.650411605834961
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.681917190551758
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.517998695373535
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.03957462310791
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.625747680664062
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.78739356994629
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.756305694580078
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.578858375549316
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.116098403930664
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.860563278198242
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.193190574645996
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.594307899475098
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 16.828462600708008
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.704941749572754
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.455050468444824
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.36860466003418
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.349775314331055
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.70627498626709
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.871268272399902
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 17.17833709716797
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 14.80077838897705
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.408899307250977
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.693997383117676
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.313859939575195
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.648258209228516
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.370893478393555
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.199593544006348
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.013833999633789
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.589041709899902
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 12.11960220336914
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 2,
            "error": 11.517253875732422
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.871395111083984
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.158737182617188
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 2,
            "error": 10.756460189819336
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 15.713741302490234
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 3,
            "error": 14.893218040466309
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.43834114074707
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.557493209838867
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 14.010138511657715
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.665903091430664
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.021387100219727
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 3,
            "error": 16.422616958618164
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 15.050116539001465
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 2,
            "error": 11.985721588134766
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 2,
            "error": 10.464839935302734
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.838651657104492
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 3,
            "error": 15.727790832519531
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 2,
            "error": 11.839994430541992
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 2,
            "error": 10.916505813598633
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 3,
            "error": 16.727781295776367
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 2,
            "error": 13.723725318908691
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 2,
            "error": 12.711516380310059
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 3,
            "error": 15.390726089477539
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 3,
            "error": 16.651399612426758
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 2,
            "error": 14.86574649810791
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 2,
            "error": 14.348517417907715
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 2,
            "error": 11.916842460632324
        },
        "lm_head": {
            "bit_width": 3,
            "error": 15.514396667480469
        }
    },
    "average_bit_width": 2.582222222222222,
    "error_threshold": 10,
    "min_quantile": 0.01,
    "max_quantile": 0.99,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.26289914562550715,
        "mmlu_results": {
            "overall_score": 0.3006134969325153,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.27,\"1\":0.34,\"2\":0.2936507937}}"
        },
        "sanity_check_string": "system\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\nuser\n\nTell a short story of humanity with happy ending\n\nIn the year 26 Jul 2024, a young and vibrant planet named Earth celebrated its 100th year anniversary of its formation."
    }
}