{
    "model_name": "HuggingFaceTB/SmolLM-135M-Instruct",
    "original_model_benchmarks": {
        "wikitext_accuracy": 0.39463618573207615,
        "mmlu_results": {
            "overall_score": 0.294478527607362,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.27,\"1\":0.31,\"2\":0.3015873016}}"
        },
        "sanity_check_string": "user\nTell a short story of humanity with happy ending\nassistant\nThe last thing I remember is the sound of footsteps, heavy and deliberate, echoing through the empty corridors of the old university. The students, still standing, groggily taking their seats, their eyes scanning the dusty shelves, their faces etched with boredom. The silence is deafening, punctuated only by the distant roar of the city outside.\n\nBut then, in a quiet moment, something clicks in my mind. It's a phrase, etched in a small,"
    },
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.32345962524414
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.938058853149414
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 2,
            "error": 17.712610244750977
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 23.1667537689209
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.152921676635742
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.079334259033203
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 2,
            "error": 19.48478126525879
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.735249519348145
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.284473419189453
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.017290115356445
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 2,
            "error": 19.3974609375
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.452739715576172
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.202232360839844
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 16.012407302856445
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.2724609375
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.550975799560547
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.44598388671875
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.140274047851562
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.314796447753906
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.89166831970215
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 2,
            "error": 15.785345077514648
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.169044494628906
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.404069900512695
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.09933853149414
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.12723731994629
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.7767391204834
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.697708129882812
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.979564666748047
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.597819328308105
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.739401817321777
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.616046905517578
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.600929260253906
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.356908798217773
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.707921981811523
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.975902557373047
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.318233489990234
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.553513526916504
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.621511459350586
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.7874755859375
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.20497703552246
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.828941345214844
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.106616973876953
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.077323913574219
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.508430480957031
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.411346435546875
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.832460403442383
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.130878448486328
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 3,
            "error": 19.8581485748291
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.190818786621094
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.027698516845703
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.671019554138184
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.024030685424805
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.200464248657227
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.699743270874023
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.165517807006836
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 3,
            "error": 21.225589752197266
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.323219299316406
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.397696495056152
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.760990142822266
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.088966369628906
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.663923263549805
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.10665512084961
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.601665496826172
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.287490844726562
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.135969161987305
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.78565788269043
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.739112854003906
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.335344314575195
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.096920013427734
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.337926864624023
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.04450225830078
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.021730422973633
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.580707550048828
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.338947296142578
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.31168556213379
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.124114990234375
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.100006103515625
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.017044067382812
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.228046417236328
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.333974838256836
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.021663665771484
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.001359939575195
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.32601547241211
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 39.01986312866211
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.210918426513672
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.76682186126709
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.681243896484375
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.10889434814453
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.991775512695312
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.548078536987305
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 2,
            "error": 16.417016983032227
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 2,
            "error": 18.229089736938477
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.013538360595703
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 21.961318969726562
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.73721694946289
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.089553833007812
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.593835830688477
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.34613037109375
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.698772430419922
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.437793731689453
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 2,
            "error": 15.159698486328125
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.255367279052734
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.581838607788086
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.571029663085938
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.06831169128418
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.474721908569336
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.666336059570312
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.570552825927734
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 3,
            "error": 18.824546813964844
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.364253997802734
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.468448638916016
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.010177612304688
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.21902084350586
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.186355590820312
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.95442008972168
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.126209259033203
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.666942596435547
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.525981903076172
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.908981323242188
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.186750411987305
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.4946346282959
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.6508731842041
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.535619735717773
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.56714630126953
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.507080078125
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.032115936279297
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.38441276550293
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 2,
            "error": 18.352127075195312
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.23382568359375
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.141895294189453
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.099225997924805
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.541276931762695
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.977783203125
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.58155632019043
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.47887420654297
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.109966278076172
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.43014907836914
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.035654067993164
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.609516143798828
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.79827117919922
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.69259262084961
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.889074325561523
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.539691925048828
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.385013580322266
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.979454040527344
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.660228729248047
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.00055503845215
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.602998733520508
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.347496032714844
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.473190307617188
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 3,
            "error": 19.773408889770508
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.05131721496582
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.935951232910156
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.318042755126953
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.110584259033203
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.56241798400879
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.419662475585938
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 2,
            "error": 17.016647338867188
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.39533042907715
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.461898803710938
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.247726440429688
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.811824798583984
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.392921447753906
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.774372100830078
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 2,
            "error": 17.19183349609375
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.34197235107422
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.29116439819336
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.105703353881836
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 2,
            "error": 17.015277862548828
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.597801208496094
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.666574478149414
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 2,
            "error": 15.806266784667969
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.015710830688477
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.477813720703125
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.93859100341797
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.275461196899414
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 2,
            "error": 17.16754722595215
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.990598678588867
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 2,
            "error": 17.353710174560547
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.879013061523438
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.322864532470703
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.900575637817383
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.2020263671875
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.483234405517578
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.982595443725586
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 2,
            "error": 20.351144790649414
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.846973419189453
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.36536979675293
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.622575759887695
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.94123077392578
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.95517349243164
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.574106216430664
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 2,
            "error": 16.21004867553711
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.798824310302734
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.35915756225586
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 3,
            "error": 19.85541534423828
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 2,
            "error": 16.69304084777832
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 2,
            "error": 16.527915954589844
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 3,
            "error": 19.475322723388672
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 3,
            "error": 22.053855895996094
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 2,
            "error": 15.900927543640137
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.27511978149414
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 2,
            "error": 26.955717086791992
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 2,
            "error": 15.669122695922852
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 2,
            "error": 15.683868408203125
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 3,
            "error": 18.890512466430664
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 22.15961265563965
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 2,
            "error": 17.88218879699707
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 2,
            "error": 15.257554054260254
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 2,
            "error": 17.698423385620117
        },
        "lm_head": {
            "bit_width": 2,
            "error": 16.293315887451172
        }
    },
    "average_bit_width": 2.6350710900473935,
    "error_threshold": 15,
    "min_quantile": 0.1,
    "max_quantile": 0.9,
    "quantized_model_benchmarks": {
        "wikitext_accuracy": 0.36092332325209037,
        "mmlu_results": {
            "overall_score": 0.29141104294478526,
            "task_scores": "{\"Task\":{\"0\":\"business_ethics\",\"1\":\"medical_genetics\",\"2\":\"formal_logic\"},\"Score\":{\"0\":0.3,\"1\":0.3,\"2\":0.2777777778}}"
        },
        "sanity_check_string": "user\nTell a short story of humanity with happy ending\nsystem\n"
    }
}