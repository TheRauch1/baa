{
    "model_name": "HuggingFaceTB/SmolLM-135M-Instruct",
    "original_model_accuracy": 0.39463618573207615,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.148056030273438
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 3,
            "error": 14.58102035522461
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 4,
            "error": 15.896235466003418
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 5,
            "error": 14.946900367736816
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.709915161132812
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 5,
            "error": 17.96445655822754
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 4,
            "error": 18.24677085876465
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.854028701782227
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 4,
            "error": 16.429187774658203
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.057788848876953
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.542155265808105
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.164562225341797
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 4,
            "error": 17.334407806396484
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 4,
            "error": 14.945972442626953
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.159879684448242
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 4,
            "error": 14.441885948181152
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.042407989501953
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.955265045166016
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.48474884033203
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.499220848083496
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 5,
            "error": 12.59366226196289
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.181045532226562
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 4,
            "error": 16.925708770751953
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.335371971130371
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.016225814819336
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.61894416809082
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.71819496154785
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 12.205511093139648
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 4,
            "error": 15.837652206420898
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 4,
            "error": 18.121044158935547
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.626121520996094
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.408580780029297
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 4,
            "error": 18.032438278198242
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.599472045898438
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.57366371154785
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.681522369384766
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 4,
            "error": 17.804410934448242
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.957260131835938
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.180419921875
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 12.122716903686523
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.695878982543945
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.97150421142578
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 4,
            "error": 17.235488891601562
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 4,
            "error": 17.53937530517578
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.697620391845703
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.374420166015625
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 4,
            "error": 18.237497329711914
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 4,
            "error": 17.040376663208008
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.852678298950195
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 4,
            "error": 15.47636604309082
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 4,
            "error": 17.27715301513672
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.609376907348633
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.480472564697266
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.838642120361328
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.489749908447266
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.12912940979004
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 4,
            "error": 18.155719757080078
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 13.184758186340332
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.121932983398438
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.512651443481445
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 4,
            "error": 18.027149200439453
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.097826957702637
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.900611877441406
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.590656280517578
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 4,
            "error": 17.08746337890625
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.223506927490234
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.566996574401855
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 4,
            "error": 17.90727424621582
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.54207992553711
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.69759178161621
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.953208923339844
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 4,
            "error": 18.311067581176758
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.43520736694336
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.53331184387207
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 4,
            "error": 18.509653091430664
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.454160690307617
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.524412155151367
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 4,
            "error": 15.316385269165039
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 12.514398574829102
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.458972930908203
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.41466522216797
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.0860595703125
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.00430679321289
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 4,
            "error": 12.86715316772461
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 4,
            "error": 14.465280532836914
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 4,
            "error": 16.333145141601562
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.145367622375488
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 16.772613525390625
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.702112197875977
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.337571144104004
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 5,
            "error": 14.302497863769531
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 4,
            "error": 13.304603576660156
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 4,
            "error": 14.640131950378418
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 3,
            "error": 13.07168197631836
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.139495849609375
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.441585540771484
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.894941329956055
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.133895874023438
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.919025421142578
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 4,
            "error": 18.50536346435547
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.20564079284668
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.383573532104492
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.660993576049805
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 4,
            "error": 13.858667373657227
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.732576370239258
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 4,
            "error": 15.912553787231445
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 4,
            "error": 13.615489959716797
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.975976943969727
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 15.660419464111328
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.811701774597168
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.80029010772705
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.951152801513672
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 4,
            "error": 13.491759300231934
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 4,
            "error": 14.02452564239502
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.597200393676758
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.041855812072754
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.800909042358398
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.07651710510254
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.669437408447266
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 4,
            "error": 14.544759750366211
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 4,
            "error": 14.155378341674805
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.91450309753418
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 4,
            "error": 16.315876007080078
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.004316329956055
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.975112915039062
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.1209774017334
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 4,
            "error": 13.411016464233398
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 4,
            "error": 14.199941635131836
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.750417709350586
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.818174362182617
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.04714584350586
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 15.470513343811035
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.14522361755371
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 4,
            "error": 14.55152416229248
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 4,
            "error": 14.792566299438477
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.277170181274414
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 16.803916931152344
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.039684295654297
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.932018280029297
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.276113510131836
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 4,
            "error": 14.483307838439941
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 4,
            "error": 15.346925735473633
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.274600982666016
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 16.803279876708984
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.14122772216797
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.900510787963867
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.361709594726562
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 4,
            "error": 17.07834243774414
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 4,
            "error": 17.040767669677734
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 3,
            "error": 12.085737228393555
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 16.872053146362305
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.529918670654297
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.437698364257812
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.720945358276367
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.552276611328125
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 4,
            "error": 17.731037139892578
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.91288948059082
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.134627342224121
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.910801887512207
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.51232147216797
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 16.290245056152344
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 4,
            "error": 17.201683044433594
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 4,
            "error": 17.845380783081055
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.58666229248047
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.028584480285645
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.129432678222656
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.884246826171875
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.033245086669922
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 4,
            "error": 17.229515075683594
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 4,
            "error": 16.930896759033203
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.23523712158203
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 17.57866668701172
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.826233863830566
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.048330307006836
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.869131088256836
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 4,
            "error": 17.128509521484375
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 4,
            "error": 18.58492088317871
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.170608520507812
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 13.269908905029297
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.102998733520508
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 4,
            "error": 17.33072853088379
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.62575912475586
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 4,
            "error": 17.593217849731445
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 4,
            "error": 18.15917205810547
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.331214904785156
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 14.354450225830078
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.566906929016113
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 4,
            "error": 17.08873176574707
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 4,
            "error": 13.699089050292969
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.87664222717285
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 4,
            "error": 15.22239875793457
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 18.268815994262695
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 12.93686294555664
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 4,
            "error": 16.428924560546875
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 4,
            "error": 16.942026138305664
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 4,
            "error": 17.63563346862793
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 4,
            "error": 16.021808624267578
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 4,
            "error": 15.89245891571045
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.64259147644043
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.89560890197754
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 5,
            "error": 14.671143531799316
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 5,
            "error": 17.376020431518555
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 5,
            "error": 17.225021362304688
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 4,
            "error": 15.991418838500977
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 4,
            "error": 16.93156623840332
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 4,
            "error": 17.45254135131836
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 4,
            "error": 18.178607940673828
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 4,
            "error": 15.153667449951172
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 5,
            "error": 16.831218719482422
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 5,
            "error": 18.66615867614746
        },
        "lm_head": {
            "bit_width": 3,
            "error": 12.136600494384766
        }
    },
    "average_bit_width": 3.928909952606635,
    "error_threshold": 12,
    "min_quantile": 0.0,
    "max_quantile": 1.0,
    "quantized_model_accuracy": 0.2532022771748799
}