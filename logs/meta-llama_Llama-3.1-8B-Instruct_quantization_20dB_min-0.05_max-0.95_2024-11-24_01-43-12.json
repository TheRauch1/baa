{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "original_model_accuracy": 0.5299508376688463,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 3,
            "error": 27.424381256103516
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.760478973388672
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.92273712158203
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 3,
            "error": 22.950679779052734
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.307098388671875
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.42321014404297
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 21.56008529663086
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 2,
            "error": 21.0732479095459
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 28.389474868774414
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.302993774414062
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.192697525024414
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.02508544921875
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.12836456298828
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 2,
            "error": 37.33299255371094
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.09100341796875
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.054492950439453
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.344907760620117
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.419981002807617
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.21776580810547
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.57979965209961
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.98333740234375
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.70278549194336
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.727725982666016
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.609333038330078
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.42835235595703
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.463272094726562
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.764192581176758
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.687835693359375
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.835468292236328
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.843259811401367
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.502521514892578
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.487232208251953
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.651447296142578
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.939006805419922
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.466121673583984
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.57906723022461
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.794933319091797
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.76533317565918
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.631744384765625
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.74901008605957
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.07769775390625
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.419279098510742
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.6044864654541
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.07682991027832
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.992700576782227
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.00062370300293
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.467025756835938
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.365266799926758
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.41067886352539
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.057296752929688
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.815139770507812
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.47232437133789
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.062076568603516
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.39159393310547
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.663105010986328
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.231895446777344
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.633291244506836
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.20751953125
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.00908660888672
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.479984283447266
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.524269104003906
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.625202178955078
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.16309356689453
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.24261474609375
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 3,
            "error": 24.41095733642578
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.120197296142578
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.196197509765625
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.633859634399414
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.74056625366211
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.134695053100586
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.086772918701172
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 3,
            "error": 24.21135711669922
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.268165588378906
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.497173309326172
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.532554626464844
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.653078079223633
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.039735794067383
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.33061408996582
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 3,
            "error": 24.548336029052734
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.086299896240234
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.51099395751953
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.6370792388916
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.64455795288086
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.146020889282227
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 3,
            "error": 25.824413299560547
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 3,
            "error": 26.140914916992188
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.725914001464844
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.575510025024414
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.84625816345215
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.89015769958496
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.343793869018555
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.67631721496582
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.049161911010742
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.812671661376953
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 20.77303123474121
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.184093475341797
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.871122360229492
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.065982818603516
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.014070510864258
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.603736877441406
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.667800903320312
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.448776245117188
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.339292526245117
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.536895751953125
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.066646575927734
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.88785171508789
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.55961036682129
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.685876846313477
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 21.55451202392578
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 3,
            "error": 23.465478897094727
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.47087860107422
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.239280700683594
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.93431854248047
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.74463653564453
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.842548370361328
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.187450408935547
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.72576904296875
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.19237518310547
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.228708267211914
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.02168083190918
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.149188995361328
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.52103614807129
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.362579345703125
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.77252960205078
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.153215408325195
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.183155059814453
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.33896827697754
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.095664978027344
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.733734130859375
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.55318260192871
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.92165756225586
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.931764602661133
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.208667755126953
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.475101470947266
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.186674118041992
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.673498153686523
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.694856643676758
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.525409698486328
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.76609992980957
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.29503631591797
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.914398193359375
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.570650100708008
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.566909790039062
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.428638458251953
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.2113037109375
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.72379493713379
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.182588577270508
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.963157653808594
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.014198303222656
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.809703826904297
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.75225830078125
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.220508575439453
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.764572143554688
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.33238983154297
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.107425689697266
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.660932540893555
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.277660369873047
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.963619232177734
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.738346099853516
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.628231048583984
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.297494888305664
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.287534713745117
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.778127670288086
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.29403305053711
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.929370880126953
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.392969131469727
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.49164581298828
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.35547637939453
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.332460403442383
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.003459930419922
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.249671936035156
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.33763313293457
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.05403709411621
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.44083023071289
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.249666213989258
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 3,
            "error": 24.01739501953125
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.685314178466797
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.620582580566406
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.365116119384766
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.126150131225586
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.392318725585938
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.15464210510254
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 22.837493896484375
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.47414779663086
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.106443405151367
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.54719352722168
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.574586868286133
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.47829818725586
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.081209182739258
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.194435119628906
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.84836769104004
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.372652053833008
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.15583610534668
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.020034790039062
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.708642959594727
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.307241439819336
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.42019271850586
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 3,
            "error": 23.09340476989746
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.224803924560547
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.809478759765625
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 3,
            "error": 21.648237228393555
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.456743240356445
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.577224731445312
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.58606719970703
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 3,
            "error": 24.226160049438477
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.759111404418945
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.397796630859375
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.01026725769043
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 4,
            "error": 26.169410705566406
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.722518920898438
        },
        "model.layers.30.self_attn.q_proj": {
            "bit_width": 3,
            "error": 23.39993667602539
        },
        "model.layers.30.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.109468460083008
        },
        "model.layers.30.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.498239517211914
        },
        "model.layers.30.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.41570281982422
        },
        "model.layers.30.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.96668815612793
        },
        "model.layers.30.mlp.up_proj": {
            "bit_width": 3,
            "error": 21.444570541381836
        },
        "model.layers.30.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.026042938232422
        },
        "model.layers.31.self_attn.q_proj": {
            "bit_width": 3,
            "error": 26.338211059570312
        },
        "model.layers.31.self_attn.k_proj": {
            "bit_width": 3,
            "error": 25.499858856201172
        },
        "model.layers.31.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.273353576660156
        },
        "model.layers.31.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.38593292236328
        },
        "model.layers.31.mlp.gate_proj": {
            "bit_width": 3,
            "error": 26.006019592285156
        },
        "model.layers.31.mlp.up_proj": {
            "bit_width": 3,
            "error": 24.965097427368164
        },
        "model.layers.31.mlp.down_proj": {
            "bit_width": 3,
            "error": 22.945173263549805
        },
        "lm_head": {
            "bit_width": 4,
            "error": 25.422964096069336
        }
    },
    "average_bit_width": 3.52,
    "error_threshold": 20,
    "min_quantile": 0.05,
    "max_quantile": 0.95,
    "quantized_model_accuracy": 0.518972841391819
}