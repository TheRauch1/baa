{
    "model_name": "HuggingFaceTB/SmolLM-135M-Instruct",
    "original_model_accuracy": 0.39463618573207615,
    "layerwise_quantization_info": {
        "model.layers.0.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.821548461914062
        },
        "model.layers.0.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.669139862060547
        },
        "model.layers.0.self_attn.v_proj": {
            "bit_width": 3,
            "error": 22.611007690429688
        },
        "model.layers.0.self_attn.o_proj": {
            "bit_width": 2,
            "error": 20.5768985748291
        },
        "model.layers.0.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.227489471435547
        },
        "model.layers.0.mlp.up_proj": {
            "bit_width": 4,
            "error": 23.47158432006836
        },
        "model.layers.0.mlp.down_proj": {
            "bit_width": 3,
            "error": 24.222732543945312
        },
        "model.layers.1.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.135234832763672
        },
        "model.layers.1.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.52945899963379
        },
        "model.layers.1.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.21352767944336
        },
        "model.layers.1.self_attn.o_proj": {
            "bit_width": 3,
            "error": 24.201194763183594
        },
        "model.layers.1.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.882394790649414
        },
        "model.layers.1.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.651479721069336
        },
        "model.layers.1.mlp.down_proj": {
            "bit_width": 3,
            "error": 21.186037063598633
        },
        "model.layers.2.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.37403106689453
        },
        "model.layers.2.self_attn.k_proj": {
            "bit_width": 4,
            "error": 26.516326904296875
        },
        "model.layers.2.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.79379653930664
        },
        "model.layers.2.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.472780227661133
        },
        "model.layers.2.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.661853790283203
        },
        "model.layers.2.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.295852661132812
        },
        "model.layers.2.mlp.down_proj": {
            "bit_width": 3,
            "error": 20.95145034790039
        },
        "model.layers.3.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.269758224487305
        },
        "model.layers.3.self_attn.k_proj": {
            "bit_width": 4,
            "error": 26.020410537719727
        },
        "model.layers.3.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.395849227905273
        },
        "model.layers.3.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.388818740844727
        },
        "model.layers.3.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.237972259521484
        },
        "model.layers.3.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.11020278930664
        },
        "model.layers.3.mlp.down_proj": {
            "bit_width": 4,
            "error": 25.399940490722656
        },
        "model.layers.4.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.06109046936035
        },
        "model.layers.4.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.76236343383789
        },
        "model.layers.4.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.956209182739258
        },
        "model.layers.4.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.939285278320312
        },
        "model.layers.4.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.796728134155273
        },
        "model.layers.4.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.115726470947266
        },
        "model.layers.4.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.35807991027832
        },
        "model.layers.5.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.569185256958008
        },
        "model.layers.5.self_attn.k_proj": {
            "bit_width": 4,
            "error": 26.434385299682617
        },
        "model.layers.5.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.031641006469727
        },
        "model.layers.5.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.161773681640625
        },
        "model.layers.5.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.66982650756836
        },
        "model.layers.5.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.264781951904297
        },
        "model.layers.5.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.570085525512695
        },
        "model.layers.6.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.302879333496094
        },
        "model.layers.6.self_attn.k_proj": {
            "bit_width": 4,
            "error": 26.51480484008789
        },
        "model.layers.6.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.963321685791016
        },
        "model.layers.6.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.331998825073242
        },
        "model.layers.6.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.544918060302734
        },
        "model.layers.6.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.26664161682129
        },
        "model.layers.6.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.640613555908203
        },
        "model.layers.7.self_attn.q_proj": {
            "bit_width": 4,
            "error": 25.966150283813477
        },
        "model.layers.7.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.680997848510742
        },
        "model.layers.7.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.499603271484375
        },
        "model.layers.7.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.615497589111328
        },
        "model.layers.7.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.062042236328125
        },
        "model.layers.7.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.535139083862305
        },
        "model.layers.7.mlp.down_proj": {
            "bit_width": 4,
            "error": 25.657814025878906
        },
        "model.layers.8.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.380231857299805
        },
        "model.layers.8.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.064128875732422
        },
        "model.layers.8.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.00156593322754
        },
        "model.layers.8.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.452499389648438
        },
        "model.layers.8.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.011520385742188
        },
        "model.layers.8.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.49317169189453
        },
        "model.layers.8.mlp.down_proj": {
            "bit_width": 4,
            "error": 25.040504455566406
        },
        "model.layers.9.self_attn.q_proj": {
            "bit_width": 4,
            "error": 25.508861541748047
        },
        "model.layers.9.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.678518295288086
        },
        "model.layers.9.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.181299209594727
        },
        "model.layers.9.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.027074813842773
        },
        "model.layers.9.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.781402587890625
        },
        "model.layers.9.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.412982940673828
        },
        "model.layers.9.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.75141143798828
        },
        "model.layers.10.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.022235870361328
        },
        "model.layers.10.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.692588806152344
        },
        "model.layers.10.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.051855087280273
        },
        "model.layers.10.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.640098571777344
        },
        "model.layers.10.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.114421844482422
        },
        "model.layers.10.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.45718002319336
        },
        "model.layers.10.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.511201858520508
        },
        "model.layers.11.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.226848602294922
        },
        "model.layers.11.self_attn.k_proj": {
            "bit_width": 4,
            "error": 25.106447219848633
        },
        "model.layers.11.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.86539649963379
        },
        "model.layers.11.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.45049285888672
        },
        "model.layers.11.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.35988998413086
        },
        "model.layers.11.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.68642234802246
        },
        "model.layers.11.mlp.down_proj": {
            "bit_width": 2,
            "error": 36.454280853271484
        },
        "model.layers.12.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.031246185302734
        },
        "model.layers.12.self_attn.k_proj": {
            "bit_width": 4,
            "error": 26.41861915588379
        },
        "model.layers.12.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.13109016418457
        },
        "model.layers.12.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.396093368530273
        },
        "model.layers.12.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.748031616210938
        },
        "model.layers.12.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.779895782470703
        },
        "model.layers.12.mlp.down_proj": {
            "bit_width": 3,
            "error": 21.515071868896484
        },
        "model.layers.13.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.298925399780273
        },
        "model.layers.13.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.508365631103516
        },
        "model.layers.13.self_attn.v_proj": {
            "bit_width": 4,
            "error": 26.189212799072266
        },
        "model.layers.13.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.909433364868164
        },
        "model.layers.13.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.17668342590332
        },
        "model.layers.13.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.900039672851562
        },
        "model.layers.13.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.672365188598633
        },
        "model.layers.14.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.870990753173828
        },
        "model.layers.14.self_attn.k_proj": {
            "bit_width": 3,
            "error": 22.013370513916016
        },
        "model.layers.14.self_attn.v_proj": {
            "bit_width": 3,
            "error": 20.29938507080078
        },
        "model.layers.14.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.489002227783203
        },
        "model.layers.14.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.580303192138672
        },
        "model.layers.14.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.898405075073242
        },
        "model.layers.14.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.359987258911133
        },
        "model.layers.15.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.91326904296875
        },
        "model.layers.15.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.692581176757812
        },
        "model.layers.15.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.957124710083008
        },
        "model.layers.15.self_attn.o_proj": {
            "bit_width": 4,
            "error": 22.997846603393555
        },
        "model.layers.15.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.530288696289062
        },
        "model.layers.15.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.728443145751953
        },
        "model.layers.15.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.370222091674805
        },
        "model.layers.16.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.251789093017578
        },
        "model.layers.16.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.73494529724121
        },
        "model.layers.16.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.314655303955078
        },
        "model.layers.16.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.38117218017578
        },
        "model.layers.16.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.713298797607422
        },
        "model.layers.16.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.76795196533203
        },
        "model.layers.16.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.287813186645508
        },
        "model.layers.17.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.60434341430664
        },
        "model.layers.17.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.279024124145508
        },
        "model.layers.17.self_attn.v_proj": {
            "bit_width": 4,
            "error": 25.051101684570312
        },
        "model.layers.17.self_attn.o_proj": {
            "bit_width": 4,
            "error": 23.685741424560547
        },
        "model.layers.17.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.59864044189453
        },
        "model.layers.17.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.797021865844727
        },
        "model.layers.17.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.358924865722656
        },
        "model.layers.18.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.4185791015625
        },
        "model.layers.18.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.105499267578125
        },
        "model.layers.18.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.078670501708984
        },
        "model.layers.18.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.417251586914062
        },
        "model.layers.18.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.94028663635254
        },
        "model.layers.18.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.780826568603516
        },
        "model.layers.18.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.29327392578125
        },
        "model.layers.19.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.831754684448242
        },
        "model.layers.19.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.644742965698242
        },
        "model.layers.19.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.4888858795166
        },
        "model.layers.19.self_attn.o_proj": {
            "bit_width": 4,
            "error": 25.663841247558594
        },
        "model.layers.19.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.054603576660156
        },
        "model.layers.19.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.834957122802734
        },
        "model.layers.19.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.180315017700195
        },
        "model.layers.20.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.990501403808594
        },
        "model.layers.20.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.558969497680664
        },
        "model.layers.20.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.65666961669922
        },
        "model.layers.20.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.666784286499023
        },
        "model.layers.20.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.134937286376953
        },
        "model.layers.20.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.97906494140625
        },
        "model.layers.20.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.384639739990234
        },
        "model.layers.21.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.80254554748535
        },
        "model.layers.21.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.74190902709961
        },
        "model.layers.21.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.8887882232666
        },
        "model.layers.21.self_attn.o_proj": {
            "bit_width": 4,
            "error": 24.200593948364258
        },
        "model.layers.21.mlp.gate_proj": {
            "bit_width": 4,
            "error": 26.097728729248047
        },
        "model.layers.21.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.240678787231445
        },
        "model.layers.21.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.751737594604492
        },
        "model.layers.22.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.153697967529297
        },
        "model.layers.22.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.360124588012695
        },
        "model.layers.22.self_attn.v_proj": {
            "bit_width": 4,
            "error": 24.601646423339844
        },
        "model.layers.22.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.93638038635254
        },
        "model.layers.22.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.639745712280273
        },
        "model.layers.22.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.84670639038086
        },
        "model.layers.22.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.584903717041016
        },
        "model.layers.23.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.23114776611328
        },
        "model.layers.23.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.32176971435547
        },
        "model.layers.23.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.66400909423828
        },
        "model.layers.23.self_attn.o_proj": {
            "bit_width": 3,
            "error": 22.539230346679688
        },
        "model.layers.23.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.339279174804688
        },
        "model.layers.23.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.627201080322266
        },
        "model.layers.23.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.55385398864746
        },
        "model.layers.24.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.529972076416016
        },
        "model.layers.24.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.98724937438965
        },
        "model.layers.24.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.767528533935547
        },
        "model.layers.24.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.916465759277344
        },
        "model.layers.24.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.13602066040039
        },
        "model.layers.24.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.819822311401367
        },
        "model.layers.24.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.31917381286621
        },
        "model.layers.25.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.694446563720703
        },
        "model.layers.25.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.743061065673828
        },
        "model.layers.25.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.3721923828125
        },
        "model.layers.25.self_attn.o_proj": {
            "bit_width": 3,
            "error": 22.270732879638672
        },
        "model.layers.25.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.210155487060547
        },
        "model.layers.25.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.631710052490234
        },
        "model.layers.25.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.360870361328125
        },
        "model.layers.26.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.472511291503906
        },
        "model.layers.26.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.06700897216797
        },
        "model.layers.26.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.302345275878906
        },
        "model.layers.26.self_attn.o_proj": {
            "bit_width": 3,
            "error": 25.437801361083984
        },
        "model.layers.26.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.201358795166016
        },
        "model.layers.26.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.835914611816406
        },
        "model.layers.26.mlp.down_proj": {
            "bit_width": 4,
            "error": 25.085681915283203
        },
        "model.layers.27.self_attn.q_proj": {
            "bit_width": 3,
            "error": 21.217554092407227
        },
        "model.layers.27.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.581111907958984
        },
        "model.layers.27.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.85924530029297
        },
        "model.layers.27.self_attn.o_proj": {
            "bit_width": 3,
            "error": 21.305601119995117
        },
        "model.layers.27.mlp.gate_proj": {
            "bit_width": 4,
            "error": 25.11761474609375
        },
        "model.layers.27.mlp.up_proj": {
            "bit_width": 4,
            "error": 24.759307861328125
        },
        "model.layers.27.mlp.down_proj": {
            "bit_width": 4,
            "error": 24.328289031982422
        },
        "model.layers.28.self_attn.q_proj": {
            "bit_width": 3,
            "error": 20.6129150390625
        },
        "model.layers.28.self_attn.k_proj": {
            "bit_width": 3,
            "error": 21.03093147277832
        },
        "model.layers.28.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.902719497680664
        },
        "model.layers.28.self_attn.o_proj": {
            "bit_width": 4,
            "error": 26.464717864990234
        },
        "model.layers.28.mlp.gate_proj": {
            "bit_width": 3,
            "error": 20.927438735961914
        },
        "model.layers.28.mlp.up_proj": {
            "bit_width": 4,
            "error": 25.53101348876953
        },
        "model.layers.28.mlp.down_proj": {
            "bit_width": 2,
            "error": 24.73928451538086
        },
        "model.layers.29.self_attn.q_proj": {
            "bit_width": 4,
            "error": 26.276987075805664
        },
        "model.layers.29.self_attn.k_proj": {
            "bit_width": 3,
            "error": 20.356952667236328
        },
        "model.layers.29.self_attn.v_proj": {
            "bit_width": 4,
            "error": 23.103120803833008
        },
        "model.layers.29.self_attn.o_proj": {
            "bit_width": 3,
            "error": 20.051734924316406
        },
        "model.layers.29.mlp.gate_proj": {
            "bit_width": 3,
            "error": 22.330013275146484
        },
        "model.layers.29.mlp.up_proj": {
            "bit_width": 3,
            "error": 20.039560317993164
        },
        "model.layers.29.mlp.down_proj": {
            "bit_width": 3,
            "error": 22.68405532836914
        },
        "lm_head": {
            "bit_width": 3,
            "error": 21.607250213623047
        }
    },
    "average_bit_width": 3.6824644549763033,
    "error_threshold": 20,
    "min_quantile": 0.05,
    "max_quantile": 0.95
}