{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve original model benchmarks\n",
    "folder_path_original_benchmarks = \"logs/original_model_benchmarks\"\n",
    "original_benchmarks = {}\n",
    "for filename in os.listdir(folder_path_original_benchmarks):\n",
    "    with open(os.path.join(folder_path_original_benchmarks, filename), \"r\") as f:\n",
    "        raw_data = json.load(f)\n",
    "        model_name = raw_data[\"model_name\"]\n",
    "        original_benchmarks[model_name] = raw_data[\"original_model_benchmarks\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "folder_path = \"logs/second_experiment\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is a JSON file\n",
    "    if filename.endswith(\".json\"):\n",
    "        # Construct the full path of the file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Open and parse the JSON file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            model_data = json.load(file)\n",
    "\n",
    "        # Store the parsed data in a dictionary using the filename as the key\n",
    "        model_name = model_data[\"model_name\"]\n",
    "        original_model_benchmark = original_benchmarks[model_name]\n",
    "        original_model_accuracy = original_model_benchmark[\"wikitext_accuracy\"]\n",
    "        quantization_data = {\n",
    "            \"error_threshold\": model_data[\"error_threshold\"],\n",
    "            \"quantized_model_benchmarks\": model_data[\"quantized_model_benchmarks\"],\n",
    "            \"average_bit_width\": model_data[\"average_bit_width\"],\n",
    "            \"min_quantile\": model_data[\"min_quantile\"],\n",
    "            \"max_quantile\": model_data[\"max_quantile\"],\n",
    "            \"layerwise_quantization_info\": model_data[\"layerwise_quantization_info\"],\n",
    "        }\n",
    "\n",
    "        # If the model name does not exist in the dictionary, add it\n",
    "        if model_name not in data:\n",
    "            data[model_name] = {\n",
    "                \"original_model_accuracy\": original_model_accuracy,\n",
    "                \"quantization_data\": [],\n",
    "            }\n",
    "\n",
    "        # Add the quantization data to the dictionary\n",
    "        data[model_name][\"quantization_data\"].append(quantization_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Subplots per model\n",
    "# For each quantile range [(0.0, 1.0), (0.01, 0.99), (0.05, 0.95)]\n",
    "# x-axis is the sqnr dB with labels and error_threshold as value\n",
    "# y-axis is the model quantized model accuracy\n",
    "\n",
    "fig, ax = plt.subplots(1, len(data), figsize=(20, 5))\n",
    "\n",
    "models_in_correct_order = [\n",
    "    \"HuggingFaceTB/SmolLM-135M-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "]\n",
    "# sort the models in the correct order\n",
    "data = {k: data[k] for k in models_in_correct_order}\n",
    "for i, (model_name, model_data) in enumerate(data.items()):\n",
    "    original_model_accuracy = model_data[\"original_model_accuracy\"]\n",
    "    quantization_data = model_data[\"quantization_data\"]\n",
    "    lines = []\n",
    "\n",
    "    for quantile_range in [(0.1, 0.9), (0.05, 0.95), (0.01, 0.99), (0.0, 1.0)]:\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        for quantization_info in quantization_data:\n",
    "            if (\n",
    "                quantization_info[\"min_quantile\"] != quantile_range[0]\n",
    "                or quantization_info[\"max_quantile\"] != quantile_range[1]\n",
    "            ):\n",
    "                continue\n",
    "            sqnr = quantization_info[\"error_threshold\"]\n",
    "            quantized_model_benchmarks = quantization_info[\"quantized_model_benchmarks\"]\n",
    "            quantized_model_accuracy = quantized_model_benchmarks[\"wikitext_accuracy\"]\n",
    "            layerwise_quantization_info = quantization_info[\n",
    "                \"layerwise_quantization_info\"\n",
    "            ]\n",
    "\n",
    "            x.append(sqnr)\n",
    "            y.append(quantized_model_accuracy)\n",
    "\n",
    "        # Sort the x and y values based on the x values\n",
    "        x, y = zip(*sorted(zip(x, y)))\n",
    "\n",
    "        # (line,) = ax[i].plot(x, y, label=f\"{quantile_range} quantile range\")\n",
    "        # plot with markers\n",
    "        (line,) = ax[i].plot(\n",
    "            x,\n",
    "            y,\n",
    "            marker=\"o\",\n",
    "            label=f\"{quantile_range} clipping range %\",\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    ax[i].axhline(y=original_model_accuracy, color=\"r\", linestyle=\"--\")\n",
    "    # add horizontal line to legend\n",
    "    lines.append(\n",
    "        mpl.lines.Line2D(\n",
    "            [0], [0], color=\"r\", linestyle=\"--\", label=\"Original Model Accuracy\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # use 0 to .60 on y axis in steps of 0.05\n",
    "    ax[i].yaxis.set_major_locator(mpl.ticker.MultipleLocator(0.05))\n",
    "    # set axis limits\n",
    "    ax[i].set_ylim(0, 0.6)\n",
    "\n",
    "    ax[i].set_title(model_name)\n",
    "    ax[i].set_xlabel(\"SQNR (dB)\")\n",
    "    ax[i].set_ylabel(\"Quantized Model Accuracy\")\n",
    "    # set location of legend down right\n",
    "    ax[i].legend(handles=lines, loc=\"lower right\")\n",
    "# sort plots by moving the last to first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Subplots per model\n",
    "# For each quantile range [(0.0, 1.0), (0.01, 0.99), (0.05, 0.95)]\n",
    "# x-axis is the sqnr dB with labels and error_threshold as value\n",
    "# y-axis is the model quantized model accuracy\n",
    "\n",
    "fig, ax = plt.subplots(1, len(data), figsize=(20, 5))\n",
    "\n",
    "models_in_correct_order = [\n",
    "    \"HuggingFaceTB/SmolLM-135M-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "]\n",
    "# sort the models in the correct order\n",
    "data = {k: data[k] for k in models_in_correct_order}\n",
    "for i, (model_name, model_data) in enumerate(data.items()):\n",
    "    original_model_accuracy = model_data[\"original_model_accuracy\"]\n",
    "    quantization_data = model_data[\"quantization_data\"]\n",
    "    lines = []\n",
    "\n",
    "    for quantile_range in [(0.1, 0.9), (0.05, 0.95), (0.01, 0.99), (0.0, 1.0)]:\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        for quantization_info in quantization_data:\n",
    "            if (\n",
    "                quantization_info[\"min_quantile\"] != quantile_range[0]\n",
    "                or quantization_info[\"max_quantile\"] != quantile_range[1]\n",
    "            ):\n",
    "                continue\n",
    "            average_bit_width = quantization_info[\"average_bit_width\"]\n",
    "            quantized_model_benchmarks = quantization_info[\"quantized_model_benchmarks\"]\n",
    "            quantized_model_accuracy = quantized_model_benchmarks[\"wikitext_accuracy\"]\n",
    "            layerwise_quantization_info = quantization_info[\n",
    "                \"layerwise_quantization_info\"\n",
    "            ]\n",
    "\n",
    "            x.append(average_bit_width)\n",
    "            y.append(quantized_model_accuracy)\n",
    "\n",
    "        # Sort the x and y values based on the x values\n",
    "        x, y = zip(*sorted(zip(x, y)))\n",
    "\n",
    "        # (line,) = ax[i].plot(x, y, label=f\"{quantile_range} quantile range\")\n",
    "        # plot with markers\n",
    "        (line,) = ax[i].plot(\n",
    "            x,\n",
    "            y,\n",
    "            marker=\"o\",\n",
    "            label=f\"{quantile_range} clipping range %\",\n",
    "        )\n",
    "        lines.append(line)\n",
    "\n",
    "    ax[i].axhline(y=original_model_accuracy, color=\"r\", linestyle=\"--\")\n",
    "    # add horizontal line to legend\n",
    "    lines.append(\n",
    "        mpl.lines.Line2D(\n",
    "            [0], [0], color=\"r\", linestyle=\"--\", label=\"Original Model Accuracy\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # use 0 to .60 on y axis in steps of 0.05\n",
    "    ax[i].yaxis.set_major_locator(mpl.ticker.MultipleLocator(0.05))\n",
    "    # set axis limits\n",
    "    ax[i].set_ylim(0, 0.6)\n",
    "\n",
    "    ax[i].set_title(model_name)\n",
    "    ax[i].set_xlabel(\"Average Bit Width\")\n",
    "    ax[i].set_ylabel(\"Quantized Model Accuracy\")\n",
    "    ax[i].legend(handles=lines, loc=\"lower right\")\n",
    "# sort plots by moving the last to first plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
